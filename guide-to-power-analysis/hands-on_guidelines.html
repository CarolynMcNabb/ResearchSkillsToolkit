<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.6.42" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />

<meta name="author" content="Cristian Mesquida" />

<title>A hands-on guide to a priori power analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<!-- htmldependencies:E3FAD763 -->
<script src="hands-on_guidelines_files/libs/kePrint-0.0.1/kePrint.js"></script>
<link href="hands-on_guidelines_files/libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <div id="quarto-toc-target"></div>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">A hands-on guide to a priori power analysis</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Cristian Mesquida </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>

<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#first-things-first" id="toc-first-things-first"><span class="header-section-number">1</span> First things first</a>
  <ul>
  <li><a href="#null-hypothesis-significance-testing-as-inferential-framework" id="toc-null-hypothesis-significance-testing-as-inferential-framework"><span class="header-section-number">1.1</span> Null Hypothesis Significance Testing as inferential framework</a></li>
  <li><a href="#what-is-statistical-power" id="toc-what-is-statistical-power"><span class="header-section-number">1.2</span> What is statistical power?</a></li>
  <li><a href="#why-high-power-is-a-desired-property-of-your-study-design" id="toc-why-high-power-is-a-desired-property-of-your-study-design"><span class="header-section-number">1.3</span> Why high power is a desired property of your study design?</a></li>
  <li><a href="#types-of-power-analyses" id="toc-types-of-power-analyses"><span class="header-section-number">1.4</span> Types of power analyses</a></li>
  <li><a href="#what-is-your-effect-size-of-interest" id="toc-what-is-your-effect-size-of-interest"><span class="header-section-number">1.5</span> What is your effect size of interest?</a></li>
  </ul></li>
  <li><a href="#things-to-consider-to-increase-power" id="toc-things-to-consider-to-increase-power"><span class="header-section-number">2</span> Things to consider to increase power</a>
  <ul>
  <li><a href="#one-sided-test-vs.-two-sided-tests" id="toc-one-sided-test-vs.-two-sided-tests"><span class="header-section-number">2.1</span> One-sided test vs. two-sided tests</a></li>
  <li><a href="#decreasing-variability-of-your-effect" id="toc-decreasing-variability-of-your-effect"><span class="header-section-number">2.2</span> Decreasing variability of your effect</a></li>
  <li><a href="#using-paired--or-repeated-measures-designs" id="toc-using-paired--or-repeated-measures-designs"><span class="header-section-number">2.3</span> Using paired- or repeated-measures designs</a></li>
  <li><a href="#including-baseline-covariates-in-ancova-model" id="toc-including-baseline-covariates-in-ancova-model"><span class="header-section-number">2.4</span> Including baseline covariates in ANCOVA model</a></li>
  <li><a href="#adjust-for-multiple-comparisons" id="toc-adjust-for-multiple-comparisons"><span class="header-section-number">2.5</span> Adjust for multiple comparisons</a></li>
  </ul></li>
  <li><a href="#sec-es-justification" id="toc-sec-es-justification"><span class="header-section-number">3</span> Effect size justification</a>
  <ul>
  <li><a href="#smallest-effect-size-of-interest-sesoi" id="toc-smallest-effect-size-of-interest-sesoi"><span class="header-section-number">3.1</span> Smallest effect size of interest (SESOI)</a></li>
  <li><a href="#expected-effect-sizes" id="toc-expected-effect-sizes"><span class="header-section-number">3.2</span> Expected effect sizes</a>
  <ul>
  <li><a href="#an-estimate-from-a-previous-study" id="toc-an-estimate-from-a-previous-study"><span class="header-section-number">3.2.1</span> An estimate from a previous study</a></li>
  <li><a href="#an-estimate-from-a-pilot-study" id="toc-an-estimate-from-a-pilot-study"><span class="header-section-number">3.2.2</span> An estimate from a pilot study</a></li>
  <li><a href="#an-estimate-from-a-meta-analysis" id="toc-an-estimate-from-a-meta-analysis"><span class="header-section-number">3.2.3</span> An estimate from a meta-analysis</a></li>
  </ul></li>
  <li><a href="#effect-size-thresholds" id="toc-effect-size-thresholds"><span class="header-section-number">3.3</span> Effect size thresholds</a>
  <ul>
  <li><a href="#cohens-d-thresholds" id="toc-cohens-d-thresholds"><span class="header-section-number">3.3.1</span> Cohen’s <em>d</em> thresholds</a></li>
  <li><a href="#field-specific-thresholds" id="toc-field-specific-thresholds"><span class="header-section-number">3.3.2</span> Field-specific thresholds</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#things-to-take-into-account-when-conducting-an-a-priori-power-analysis" id="toc-things-to-take-into-account-when-conducting-an-a-priori-power-analysis"><span class="header-section-number">4</span> Things to take into account when conducting an a priori power analysis</a>
  <ul>
  <li><a href="#adjusting-for-uncertainty-and-bias" id="toc-adjusting-for-uncertainty-and-bias"><span class="header-section-number">4.1</span> Adjusting for uncertainty and bias</a>
  <ul>
  <li><a href="#safeguard-power-analysis" id="toc-safeguard-power-analysis"><span class="header-section-number">4.1.1</span> Safeguard power analysis</a></li>
  <li><a href="#bias-adjusted-effect-size-estimate" id="toc-bias-adjusted-effect-size-estimate"><span class="header-section-number">4.1.2</span> Bias-adjusted effect size estimate</a></li>
  </ul></li>
  <li><a href="#study-context" id="toc-study-context"><span class="header-section-number">4.2</span> Study context</a></li>
  </ul></li>
  <li><a href="#sec-power-analysis" id="toc-sec-power-analysis"><span class="header-section-number">5</span> Conducting an a priori power analysis</a>
  <ul>
  <li><a href="#paired-sample-design" id="toc-paired-sample-design"><span class="header-section-number">5.1</span> Paired-sample design</a>
  <ul>
  <li><a href="#using-pwr.t.test" id="toc-using-pwr.t.test"><span class="header-section-number">5.1.1</span> Using <code>pwr.t.test()</code></a></li>
  <li><a href="#simulation-approach" id="toc-simulation-approach"><span class="header-section-number">5.1.2</span> Simulation approach</a></li>
  </ul></li>
  <li><a href="#unpaired-sample-design" id="toc-unpaired-sample-design"><span class="header-section-number">5.2</span> Unpaired-sample design</a>
  <ul>
  <li><a href="#using-pwr.t.test-1" id="toc-using-pwr.t.test-1"><span class="header-section-number">5.2.1</span> Using <code>pwr.t.test()</code></a></li>
  <li><a href="#simulation-approach-1" id="toc-simulation-approach-1"><span class="header-section-number">5.2.2</span> Simulation approach</a></li>
  </ul></li>
  <li><a href="#designs-with-more-than-two-levels" id="toc-designs-with-more-than-two-levels"><span class="header-section-number">5.3</span> Designs with more than two levels</a></li>
  <li><a href="#one-factor-repeated-measures-design" id="toc-one-factor-repeated-measures-design"><span class="header-section-number">5.4</span> One-factor repeated-measures design</a>
  <ul>
  <li><a href="#simulation-using-aov" id="toc-simulation-using-aov"><span class="header-section-number">5.4.1</span> Simulation using <code>aov()</code></a></li>
  <li><a href="#simulation-using-superpower" id="toc-simulation-using-superpower"><span class="header-section-number">5.4.2</span> Simulation using <code>Superpower</code></a></li>
  </ul></li>
  <li><a href="#one-factor-between-subject-design" id="toc-one-factor-between-subject-design"><span class="header-section-number">5.5</span> One-factor between-subject design</a>
  <ul>
  <li><a href="#simulation-using-lm-2" id="toc-simulation-using-lm-2"><span class="header-section-number">5.5.1</span> Simulation using <code>lm()</code></a></li>
  <li><a href="#simulation-using-superpower-1" id="toc-simulation-using-superpower-1"><span class="header-section-number">5.5.2</span> Simulation using <code>Superpower</code></a></li>
  </ul></li>
  <li><a href="#two-factor-repeated-measures-design" id="toc-two-factor-repeated-measures-design"><span class="header-section-number">5.6</span> Two-factor repeated-measures design</a></li>
  <li><a href="#two-factor-mixed-design" id="toc-two-factor-mixed-design"><span class="header-section-number">5.7</span> Two-factor mixed design</a>
  <ul>
  <li><a href="#simulation-using-lm-including-time-as-a-covariate" id="toc-simulation-using-lm-including-time-as-a-covariate"><span class="header-section-number">5.7.1</span> Simulation using <code>lm()</code> including time as a covariate</a></li>
  </ul></li>
  <li><a href="#one-factor-between-subject-design-with-a-continuous-predictor" id="toc-one-factor-between-subject-design-with-a-continuous-predictor"><span class="header-section-number">5.8</span> One-factor between-subject design with a continuous predictor</a></li>
  <li><a href="#equivalence-tests" id="toc-equivalence-tests"><span class="header-section-number">5.9</span> Equivalence tests</a></li>
  <li><a href="#minimum-effect-tests" id="toc-minimum-effect-tests"><span class="header-section-number">5.10</span> Minimum-effect tests</a></li>
  <li><a href="#general-linear-mixed-models" id="toc-general-linear-mixed-models"><span class="header-section-number">5.11</span> (General) Linear Mixed Models</a>
  <ul>
  <li><a href="#summary-statistics-based-approach" id="toc-summary-statistics-based-approach"><span class="header-section-number">5.11.1</span> Summary-statistics-based approach</a></li>
  <li><a href="#traditional-approach-work-in-progress" id="toc-traditional-approach-work-in-progress"><span class="header-section-number">5.11.2</span> Traditional approach (work in progress)</a></li>
  <li><a href="#simulation-based-power-analysis-work-in-progress" id="toc-simulation-based-power-analysis-work-in-progress"><span class="header-section-number">5.11.3</span> Simulation-based power analysis (work in progress)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#transparency-and-computational-reproducibility" id="toc-transparency-and-computational-reproducibility"><span class="header-section-number">6</span> Transparency and computational reproducibility</a></li>
  </ul>
</nav>
<p><strong>Note</strong></p>
<p>This document focuses on conducting a priori power analyses as a method for justifying sample sizes in hypothesis-testing studies. For other sample size justifications, readers are referred to <span class="citation" data-cites="lakens_justification_2022">Daniël Lakens (<a href="#ref-lakens_justification_2022" role="doc-biblioref">2022a</a>)</span>. The scope of this document is limited to a priori power analyses for tests that fall under the General Linear Model (GLM) framework, including <em>t</em>-tests, analysis of variance (ANOVA), analysis of covariance (ANCOVA), equivalence tests and minimum-effect tests. This document does not present original content. Rather, it compiles material from existing sources, including blog posts (<a href="https://solomonkurz.netlify.app/blog/2023-04-12-boost-your-power-with-baseline-covariates/">Solom Kurz’s</a>, <a href="https://daniellakens.blogspot.com/2020/03/effect-sizes-and-power-for-interactions.html">Daniël Lakens’</a> blogs), online resources (<a href="https://lmu-osc.github.io/Simulations-for-Advanced-Power-Analyses/LM1.html">LMU Open Science Center</a>, <a href="https://psyteachr.github.io">PsyteachR</a> and <a href="https://aaroncaldwell.us/SuperpowerBook/">Power Analysis with Superpower</a>) as well as published articles—all of which are cited throughout the document. The aim is to provide students and researchers with resources that explain the importance designing studies with adequate power to reject the presence or absence of meaningful effects and assist them in conduct valid and reproducible a priori power analyses.</p>
<p><strong>Disclaimer</strong></p>
<p>These guidelines are intended as a framework and introduction—not as definitive proof. There may be inaccuracies in this tutorial. If you notice any errors, please don’t hesitate to reach out. I strongly encourage researchers to collaborate with (applied) statisticians to ensure their a priori power analyses are methodologically sound.</p>
<p><strong>Required packages</strong></p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)               <span class="co"># combine ggplots</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(metafor)                 <span class="co"># calculate effect sizes</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)                   <span class="co"># generation of the document</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)               <span class="co"># wrangle and tidy data</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)              <span class="co"># create tables</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pwr)                     <span class="co"># conduct power analyses</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)                   <span class="co"># perform iterative tasks</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(faux)                    <span class="co"># simulate factorial data</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MBESS)                   <span class="co"># calculate effect sizes</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(criticalESvalue)         <span class="co"># calculate critical effect sizes</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(BUCSS)                   <span class="co"># adjust for publication bias and uncertainty</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)                   <span class="co"># tidy the result of a test  </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)                 <span class="co"># pairwise comparisons</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Superpower)              <span class="co"># conduct power analysis for factorial designs</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(TOSTER)                  <span class="co"># perform equivalence tests</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)                    <span class="co"># perform linear mixed model analysis</span></span></code></pre></div>
</div>
<section id="first-things-first" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> First things first</h1>
<section id="null-hypothesis-significance-testing-as-inferential-framework" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Null Hypothesis Significance Testing as inferential framework</h2>
<p>Researchers are often interested in making dichotomous claims (e.g., “the intervention is superior to control”; “the intervention is not superior to the control”) while controlling the probability that such claims are wrong. One common tool for making such claims is the Null Hypothesis Significance Testing (NHST) framework, which relies on <em>p</em>-values to guide decision-making. When conducting a hypothesis test there are 4 potential outcomes:</p>
<ul>
<li><p>True positive: the statistical test yields a significant <em>p</em>-value when there is a true effect or difference between the groups/conditions being compared. In this case the test correctly rejects the null hypothesis of no difference.</p></li>
<li><p>True negative: the statistical test yields a non-significant <em>p</em>-value when there is no true effect or difference between the groups being compared. In this case the test correctly fails to reject the null hypothesis of no difference.</p></li>
<li><p>False positive or type I error (usually set to alpha = 0.05): A type I error occurs when a statistical test yields a significant <em>p</em>-value (<em>p</em> &lt; alpha) even though there is no true effect or difference between the groups being compared. In this case the test wrongly rejects the null hypothesis of no difference committing a type I error. Researchers can control the probability of making a type I error by setting a thresholds, commonly setting alpha to 0.05 (5%) before conducting a hypothesis test. That means that in the long run, no more than 5% of tests will yield false positives.</p></li>
<li><p>False negative or type II error (denoted by β): A type II error occurs when a statistical test fails to detect a true effect—that is, it yields a non-significant <em>p</em>-value when there is a true effect or difference between the groups being compared. In this case the test fails to reject the hypothesis of no difference committing a type II error. Researchers can reduce the risk of type II error by designing studies with high statistical power (hereafter referred to as power). Power is defined as 1-β, where β is usually set to 0.2 (20%) and ensures than in the long run, no more than 20% of tests will yield a false negative.</p></li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In NHST, the goal of a test is to evaluate whether the data provide sufficient evidence to reject the null hypothesis (H<sub>0</sub>). Typically, H<sub>0</sub> specifies that there is no effect or difference (i.e., H<sub>0</sub> = 0). However, H<sub>0</sub> can also be set to non-zero value or even defined as a range, depending on the research question. researchers specify a range of non-zero values that constitute H<sub>0</sub> (see <span class="citation" data-cites="lakens_value_preregistration">Daniel Lakens (<a href="#ref-lakens_value_preregistration" role="doc-biblioref">2019</a>)</span> for a detailed explanation on different types of H<sub>0</sub> and <span class="citation" data-cites="lakens_equivalence_2017">Daniël Lakens (<a href="#ref-lakens_equivalence_2017" role="doc-biblioref">2017</a>)</span> for equivalence tests). When the test leads to the rejection of H0, researchers conclude that the alternative hypothesis (H<sub>1</sub>) is supported by data, which includes all values not covered by H<sub>0</sub>.</p>
</div>
</div>
<p>In essence, if researchers aim to make claims while controlling how often they will be wrong in the long run, they should use NHST to test hypotheses and ensure that both type I and type II errors are appropriately controlled.</p>
</section>
<section id="what-is-statistical-power" class="level2" data-number="1.2">
<h2 data-number="1.2"><span class="header-section-number">1.2</span> What is statistical power?</h2>
<p>Power is defined as the probability that a statistical test will yield a significant <em>p</em>-value given that a true effect exists (i.e., the null hypothesis is false). It depends on several factors: the effect size, the total sample size (N), the statistical test and α. For a given α, the power of a test will increase as the effect size and/or the sample size increases. In the frequentist framework, power is interpreted as a long-term probability. That is, if you were going to repeat the same experiment many times under identical conditions where the effect size is fixed, power represents the proportion of studies that would yield a significant <em>p</em>-value. For example, a test with 80% power is expected to detect the effect 80 out of 100 times on average. If you want to plan a study with 80% power, a power analysis will answer the following question:</p>
<blockquote>
<p>“If I repeated my experiment 1000 times, what sample size would allow me to reject the null hypothesis 80% of the time?”</p>
</blockquote>
<p>Let’s illustrate the concept of power using an unpaired <em>t</em>-test with an effect size <em>d</em> = 0.4. Unless otherwise specified, we assume α = 0.05 throughout the article.</p>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)                 </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                    <span class="co"># number of simulations</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>p_values <span class="ot">&lt;-</span> <span class="fu">numeric</span>(nsims)       <span class="co"># create an empty vector</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">200</span>                         <span class="co"># total sample size</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>smd <span class="ot">&lt;-</span> <span class="fl">0.4</span>                       <span class="co"># standardized mean difference</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">1</span>                          <span class="co"># standard deviation (SD)</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulation</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsims) {</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>intervention <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> smd, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>test_result <span class="ot">&lt;-</span> <span class="fu">t.test</span>(intervention, </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>                      control, </span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                      <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>p_values[i] <span class="ot">&lt;-</span> test_result<span class="sc">$</span>p.value</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
</div>
<p>Assuming a true effect size of <em>d =</em> 0.4, a standard deviation (SD) of 1, and an N of 200 (100 per group), such study design would achieve a power of 80.4. In other words, repeating the same experiment many times under the same conditions, approximately 80.4% of the resulting <em>p</em>-values would fall below 0.05. This is illustrated in the histogram shown in <a href="#fig-figure1" class="quarto-xref">Figure 1</a>, where roughly 80% of the <em>p</em>-values are smaller than 0.05, reflecting the power of the test. Under the alternative hypothesis, the greater the power of a test, the larger the proportion of <em>p</em>-values that fall below 0.05, resulting in a more left-skewed distribution of <em>p</em>-values.</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(p_values, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">main =</span> <span class="cn">NULL</span>, <span class="at">xlab =</span> <span class="st">&quot;p-value&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.05</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure1" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure1-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 1: Distribution of p-values when there is a true effect and power is 80%.
</figcaption>
</figure>
</div>
</div>
</div>
<p>When there is no true effect, the power of a test is equivalent to α or the Type I error rate. In other words, if a researcher conducts a study under the null hypothesis (i.e., assuming no difference between two groups), the probability of obtaining a significant <em>p</em>-value is 5% (α is set to 0.05). This is because, by definition, 5% of <em>p</em>-values will fall below 0.05 just by chance alone, even when there is no true effect. Under the null hypothesis, <em>p</em>-values follow a uniform distribution over the range 0 to 1, meaning all values are equally likely in the lung run. the range 0-1 have the same probability of being observed in the long run. To illustrate this, let’s run a simulation and observe how often type I errors occur under the null hypothesis.</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0509090</span>)          </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                <span class="co"># number of simulations  </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>p_values <span class="ot">&lt;-</span> <span class="fu">numeric</span>(nsims)   <span class="co"># create an empty vector</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>smd <span class="ot">&lt;-</span> <span class="dv">0</span>                     <span class="co"># standardized effect size of 0</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">200</span>                     <span class="co"># total sample size</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulation</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsims) {</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>intervention <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> smd, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>test_result <span class="ot">&lt;-</span> <span class="fu">t.test</span>(intervention, </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>                      control, </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>                      <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                      <span class="at">sig.level =</span> <span class="fl">0.05</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>p_values[i] <span class="ot">&lt;-</span> test_result<span class="sc">$</span>p.value </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> <span class="fl">0.05</span>)<span class="sc">*</span><span class="dv">100</span> </span></code></pre></div>
</div>
<p>Assuming a true effect size of 0 and an N of 200 (100 per group), such study design would achieve a power of 5.5, which is approximately equal to α or type I error rate. This is illustrated in the histogram shown in <a href="#fig-figure2" class="quarto-xref">Figure 2</a>, where roughly 5% of the <em>p</em>-values are smaller than 0.05, reflecting the type I error rate of the test.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(p_values, <span class="at">breaks =</span> <span class="dv">50</span>, <span class="at">main =</span> <span class="cn">NULL</span>, <span class="at">xlab =</span> <span class="st">&quot;p-value&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.05</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">2</span>)  <span class="co"># vertical line at 0.05</span></span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure2" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure2-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 2: Distirbution of p-values under the null hypothesis where power is approximately 5%.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="why-high-power-is-a-desired-property-of-your-study-design" class="level2" data-number="1.3">
<h2 data-number="1.3"><span class="header-section-number">1.3</span> Why high power is a desired property of your study design?</h2>
<p>Designing studies with high power to detect the effect size of interest increases the informational value of studies for three main reasons:</p>
<ul>
<li><p>When a study design is under-powered to detect the effect size of interest, a non-significant <em>p</em>-value provides little information since it may simply reflect insufficient sensitivity (i.e., power) rather than the absence of an effect. For example, suppose two researchers compare the difference between the two same interventions with an unpaired <em>t</em>-test, where the true effect size is <em>d<sub>s</sub></em> = 0.2. Researcher A recruits N = 40 (20 per each group), while researcher B recruits N = 800 (400 per each group).</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.t.test</span>(<span class="at">n =</span> <span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">400</span>),</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">d =</span> <span class="fl">0.2</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">sig.level =</span> <span class="fl">0.05</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     Two-sample t test power calculation 

              n = 20, 400
              d = 0.2
      sig.level = 0.05
          power = 0.09456733, 0.80649728
    alternative = two.sided

NOTE: n is number in *each* group</code></pre>
</div>
</div>
<p>Researcher A’s study design would achieve approximately 10% power, meaning that only 1 out of 10 replications is expected to yield a significant result even though a real difference between two interventions exists. In contrast, researcher B’s study design achieves 80% power. Thus if researcher B’s test yields a non-significant <em>p</em>-value, she can be more confident that the effect is <em>likely</em> absent or smaller than the expected effect size.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Although non-significant <em>p</em>-values from highly-powered study designs are more informative, non-significant <em>p</em>-values should never be interpreted as evidence of absence. To make such a claim, researchers must use equivalence tests, which are specifically designed to test for the absence of an effect within a defined range.</p>
</div>
</div></li>
<li><p>Studies designed with high statistical power yield narrower 95% confidence intervals (CI). This improves precision and reduces the uncertainty around effect sizes estimates. <a href="#fig-figure3" class="quarto-xref">Figure 3</a> depicts the confidence intervals from five replicated studies conducted with two different sample sizes (N of 40 and N of 200), to detect a true effect size of 0.3.</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure3" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure3-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 3: Width of 95% confidence intervals for studies with a total sample sizes of N = 40 and N = 200. Dashed black lines represents a true effect size d = 0.3
</figcaption>
</figure>
</div>
</div>
</div>
<p>Although we simulated the data with a true (population) effect size of <em>d =</em> 0.3, the wide confidence intervals indicate that observed effect sizes have considerable uncertainty, particularly for smaller sample sizes. All values within a confidence interval are plausible values of the true (population) effect size. For instance, a study that yields a 95% CI ranging from -0.75 to 0.5 (i.e., study 2 in N = 40) is largely uninformative because the interval includes both positive and negative effects, as well as the possibility of no effect at all.</p>
<p>To sum up, designing studies with adequate power to detect the effect size of interest increases the informational value of studies in three ways: a) high-powered study designs because studies have a higher probability of detecting a true effect or difference when it exists, b) non-significant results become informative and c) confidence intervals tend to be narrower, providing more precise effect size estimates.</p>
</section>
<section id="types-of-power-analyses" class="level2" data-number="1.4">
<h2 data-number="1.4"><span class="header-section-number">1.4</span> Types of power analyses</h2>
<p>We briefly discuss three types of power analyses below, but readers are referred to <span class="citation" data-cites="lakens_justification_2022">Daniël Lakens (<a href="#ref-lakens_justification_2022" role="doc-biblioref">2022a</a>)</span> for a comprehensive overview of the topic.</p>
<ul>
<li><p><strong>A priori power analysis</strong>: it is performed before data collection to estimate the required sample size to achieve a desired level of power given the expected effect size, the planned test and the chosen alpha level. The goal of an a priori power analysis is to control type II error rates, or in other words, to limit the probability of observing a non-significant effect, assuming there is an effect of an specific size.</p></li>
<li><p><strong>Sensitivity power analysis</strong>: it is used to assess which effect sizes could be reliably detected given a sample size, the statistical test and α. This type of power analysis is particularly useful when researchers are uncertain about the expected effect size, are working with pre-existing data, are constrained by a limited number of participants or are doing exploratory research. Sensitivity analyses are often presented as power curves, which illustrates the relationship between effect sizes and the achieved power of the test for a given sample size and α (Figure 4). For example, suppose resource constraints only allow us to recruit an N of 50 participants in a study comparing two independent groups. Figure 4 reveals that with this sample size, only effect sizes larger than <em>d</em> = 0.8 can be reliably detected with adequate power (i.e., ≥ 80%).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure4" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure4-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 4: Sensitivity power analysis for effect sizes randing from d = 0.4 to 1 with N = 50 using an unpaired t-test
</figcaption>
</figure>
</div>
</div>
</div></li>
<li><p>P<strong>ost hoc power analysis</strong>: it is performed after data collection to estimate the power of the study as a means to justify a non-significant effect, typically using the observed effect size, sample size and alpha level from the study. However, this type of power analysis is considered bad practice and researchers should not report such analysis. This is because the information provided by the post hoc power analysis is redundant. To compute post hoc power, all is needed is the observed <em>p</em>-value and alpha level. For this reason, calculating post hoc power does not provide new information that it is not already provided by the <em>p</em>-value and α <span class="citation" data-cites="lenth_posthocpower_2007 christogiannis_post-hoc yuan_posthoc">(<a href="#ref-lenth_posthocpower_2007" role="doc-biblioref">Lenth 2007</a>; <a href="#ref-christogiannis_post-hoc" role="doc-biblioref">Christogiannis et al. 2022</a>; <a href="#ref-yuan_posthoc" role="doc-biblioref">Yuan and Maxwell 2005</a>)</span>. <span class="citation" data-cites="lenth_posthocpower_2007">Lenth (<a href="#ref-lenth_posthocpower_2007" role="doc-biblioref">2007</a>)</span> provides an R function to compute post hoc power for an unpaired <em>t</em>-test, which is as follows:</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>posthoc_power <span class="ot">&lt;-</span> <span class="cf">function</span>(p_value, df, alpha_level) {</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  delta <span class="ot">=</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span> <span class="sc">-</span> p_value <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> df)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  crit_val <span class="ot">=</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span> <span class="sc">-</span> alpha_level <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> df)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  power <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="at">q =</span> crit_val, <span class="at">df =</span> df, <span class="at">ncp =</span> delta) <span class="sc">+</span> <span class="fu">pt</span>(<span class="sc">-</span>crit_val, df, delta)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(power)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<p>If we assume a <em>p</em>-value = 0.07, degrees of freedom = 38 (N = 50; df = 50-2) and α = 0.05, the posthoc_power() function returns a post hoc power of:</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">posthoc_power</span>(<span class="at">p_value =</span> <span class="fl">0.07</span>, <span class="at">df =</span> <span class="dv">38</span>, <span class="at">alpha_level =</span> <span class="fl">0.05</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4433432</code></pre>
</div>
</div>
<p>Studies that yield non-significant <em>p</em>-values typically have less than 50% power, whereas a a study that yields a <em>p</em>-value of 0.05 will have approximately 50% power. This relationship can be visualized by plotting post hoc power as a function of <em>p</em>-values ranging from 0 to 1.</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="dv">38</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>df_power <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">p_value =</span> p_value,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(p_value, <span class="sc">~</span> <span class="fu">posthoc_power</span>(.x, df, alpha_level))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_power, <span class="fu">aes</span>(<span class="at">y =</span> p_value, <span class="at">x =</span> power)) <span class="sc">+</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.05</span>, <span class="at">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(<span class="fu">italic</span>(p)<span class="sc">-</span>value)) <span class="sc">+</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Post hoc power&quot;</span>) </span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure5" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure5-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 5: Achieved power as a function of p-values for a two-group design with N = 50 and alpha level = 0.05.
</figcaption>
</figure>
</div>
</div>
</div></li>
</ul>
<p>As illustrated in <a href="#fig-figure5" class="quarto-xref">Figure 5</a>, whenever a <em>p</em>-value is non-significant (greater than the conventional alpha level, indicated by the red line), the corresponding post hoc power is typically less than 50%. Therefore, conducting a post hoc power analysis to justify a non-significant result is uninformative since tests that yield a non-significant <em>p</em>-value will typically be under-powered when evaluated post hoc.</p>
</section>
<section id="what-is-your-effect-size-of-interest" class="level2" data-number="1.5">
<h2 data-number="1.5"><span class="header-section-number">1.5</span> What is your effect size of interest?</h2>
<p>When researchers conduct an a priori power analysis the aim is to design a study that has adequate power to detect the effect size of interest. But what do we really mean by <em>effect size of interest</em>? The effect size of interest corresponds to the difference between treatments or interventions or conditions that researchers consider practically, theoretically, or clinically relevant and, hence, of interest. As <span class="citation" data-cites="senn_2021">Senn (<a href="#ref-senn_2021" role="doc-biblioref">2021</a>)</span> argued, “the difference one would not like to miss”. Best case would be the effect size of interest corresponds to the smallest effect size of interest (SESOI) <span class="citation" data-cites="lakens_justification_2022">(<a href="#ref-lakens_justification_2022" role="doc-biblioref">Daniël Lakens 2022a</a>)</span>. In practice, however, it is often based on an expected effect size (see <a href="#sec-es-justification" class="quarto-xref">Section 3</a>). The most challenging aspect of an a priori power analysis is the selection of the effect size, which is inherently subjective and therefore requires explicit justification.</p>
<p>Depending on the study goal or hypothesis, the intervention effect might correspond to a mean difference between two groups or conditions at a specific time point, or an interaction effect where the effect of a factor is moderated by the effect of a second factor. This difference can be expressed in absolute (e.g., mean difference) or relative terms (e.g., hazard ratio, risk ratio). Absolute ES can be presented in unstandardised (raw units) or standardised form (e.g., Cohen’s <em>d</em> ). Among standardized effect sizes, one of the most commonly used in psychology and social sciences is Cohen’s <em>d</em>, which represents a standardized mean difference—calculated by diving the mean difference between two interventions or conditions by the standard deviation (SD). Cohen’s <em>d</em> actually refers to a family of related effect size measures, differentiated by subscripts such as <em>d<sub>s</sub></em>, <em>d<sub>rm</sub></em> or <em>d<sub>av</sub></em> depending on the study design (between- or within-subject design) and type of standardized used (see <span class="citation" data-cites="lakens_calculating_es">Daniel Lakens (<a href="#ref-lakens_calculating_es" role="doc-biblioref">2013</a>)</span> and <span class="citation" data-cites="jane_guidelines_es">Jané et al. (<a href="#ref-jane_guidelines_es" role="doc-biblioref">2024</a>)</span> for a gentile introduction to how to calculate standardized effect sizes).</p>
<p>Unless otherwise specified, throughout this article and in the accompanying code snippets, we use <code>smd</code> as an equivalent of a Cohen’s <em>d</em> and represents the mean difference between two interventions or conditions divided by SD. For example, if <code>smd</code> = 0.4 and SD is assumed to be 1, this corresponds to a Cohen’s <em>d</em> of 0.4 (0.4/1). As we will see in the <a href="#sec-power-analysis" class="quarto-xref">Section 5</a>, a priori power analyses can be conducted using either standardized effect sizes or raw effect sizes (i.e., means and SD).</p>
</section>
</section>
<section id="things-to-consider-to-increase-power" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Things to consider to increase power</h1>
<p>Besides increasing the sample size, there are other options that researchers can use to increase the statistical power of their study designs.</p>
<section id="one-sided-test-vs.-two-sided-tests" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> One-sided test vs. two-sided tests</h2>
<p>One-sided tests usually achieve higher power than two-sided tests, assuming the same sample size, test and α. This is because the critical region for rejecting the null hypothesis is concentrated in one tail of the distribution, making it easier to detect an effect in the predicted direction. To illustrate this, let’s conduct two a priori power analyses using the following parameters: a Cohen’s <em>d</em> of 0.2, an independent <em>t</em>-test, an N of 200 and alpha level of 0.05.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">200</span> <span class="co"># sample size</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>smd <span class="ot">&lt;-</span> <span class="fl">0.2</span> <span class="co"># effect size</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># alpha level</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>type <span class="ot">&lt;-</span> <span class="st">&quot;two.sample&quot;</span> <span class="co"># type of t-test </span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>one_sided <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">d =</span> smd, </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>                        <span class="at">sig.level =</span> alpha, </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>                        <span class="at">type =</span> type, </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>                        <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>two_sided <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>                        <span class="at">d =</span> smd, </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>                        <span class="at">sig.level =</span> alpha, </span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>                        <span class="at">type =</span> type, </span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>                        <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>one_sided<span class="sc">$</span>power</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4069209</code></pre>
</div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>two_sided<span class="sc">$</span>power</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2906459</code></pre>
</div>
</div>
<p>The results show that the one-sided test achieves a power of 0.4 whereas the two-sided test achieves a power of 0.3. This demonstrates the efficiency gain of one-sided tests when a directional hypothesis is justified. However, it is essential to ensure that the directionality of the hypothesis is appropriately aligned with the choice of the test. If there is no theoretical or empirical justification for expecting an effect in a specific direction, a two-sided test should be used. Furthermore, the directionality of the hypothesis should ideally be preregistered prior to data collection. Preregistration promotes transparency and can prevent practices such as switching from a two-sided to a one-sided test post hoc in order to achieve statistical significance. Such practices.</p>
</section>
<section id="decreasing-variability-of-your-effect" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Decreasing variability of your effect</h2>
<p>Standardized mean differences, such as those in the Cohen’s <em>d</em> family of effect sizes), are calculated by divinding the mean difference between two time points, conditions or groups by the standard deviation. For example, in a two-group design, this is typically expressed as Cohen’s <em>d</em><sub>s</sub>, which represents the mean difference between two groups (intervention (INT) vs. control (CON)) divided by the pooled standard deviation (SD). Cohen’s <em>d<sub>s</sub></em> can be calculated as <span class="citation" data-cites="lakens_calculating_es">(<a href="#ref-lakens_calculating_es" role="doc-biblioref">Daniel Lakens 2013</a>)</span>:</p>
<p><span class="math display">\[
d_{s} = \frac{\text{Mean}_{\text{INT}} - \text{Mean}_{\text{CON}}}{\text{SD}_{\text{Pooled}}}
\]</span></p>
<p>If the mean difference between two groups is 10 and the SD<sub>pooled</sub> is 20, then <em>d<sub>s</sub></em> = 0.2. However, if SD<sub>pooled</sub> = 15, <em>d<sub>s</sub></em> = 0.67. This illustrates that the standardized mean difference increases either when the mean difference increases or when the variability in the data (SD) decreases. Thus, researchers can increase power by (1) increasing the mean difference between groups or measurements, and/or (2) reducing SD.</p>
</section>
<section id="using-paired--or-repeated-measures-designs" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> Using paired- or repeated-measures designs</h2>
<p>Study designs based on paired or repeated-measures data typically achieve higher power than unpaired or between-subject data. This advantage arises because the same participants contribute multiple data points, introducing correlation between measurements. The stronger this correlation, the greater the power. Paired designs increase power because the correlation reduces SD of differences and therefore the standard errors.</p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>            <span class="co"># number of simulations</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">50</span>                  <span class="co"># sample size</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="fl">0.2</span>               <span class="co"># mean group 1</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="fl">0.4</span>               <span class="co"># mean group 2</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">1</span>                  <span class="co"># common SD</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.4</span>, <span class="fl">0.8</span>)    <span class="co"># vector of correlations</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation function</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(rho) {</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;pre&quot;</span>, <span class="st">&quot;post&quot;</span>)),</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> N,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2),</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="dv">1</span>,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    ) </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lm</span>(df<span class="sc">$</span>post <span class="sc">-</span> df<span class="sc">$</span>pre <span class="sc">~</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pull</span>(p.value)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Run for all sample sizes</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">r =</span> rho,</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                        <span class="at">power =</span> <span class="fu">map_dbl</span>(rho, simulate_power))</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<caption>Achieved power for an unpaired t-test assuming different correlations.</caption>
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">r</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.0</td>
<td style="text-align: right;">0.170</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.4</td>
<td style="text-align: right;">0.245</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.8</td>
<td style="text-align: right;">0.573</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
<section id="including-baseline-covariates-in-ancova-model" class="level2" data-number="2.4">
<h2 data-number="2.4"><span class="header-section-number">2.4</span> Including baseline covariates in ANCOVA model</h2>
<p>This section is based on <a href="https://solomonkurz.netlify.app/blog/2023-04-12-boost-your-power-with-baseline-covariates/">Solom Kurz’s blog post</a>.</p>
<p>Adding baseline covariates to an ANOVA model-resulting in an ANCOVA model-will generally increase power in comparison to an ANOVA model. This is because ANCOVA adjusts for baseline differences between groups, reducing residual variance and thereby increasing the sensitivity to detect group differences. <span class="citation" data-cites="borm_2007">Borm, Fransen, and Lemmens (<a href="#ref-borm_2007" role="doc-biblioref">2007</a>)</span> presented an approximate sample size adjustment for cases where the primary outcome is measured both pre- and post-intervention. The adjustment is based on the correlation (rho) between the pre- and post-measurements:</p>
<p><span class="math display">\[
N_{\text{adjusted}} = N_{\text{ANOVA}} \times (1 - \rho^2)
\]</span></p>
<p>where <em>N</em><sub>ANOVA</sub> is the sample size required under the ANOVA model, rho is the correlation between the pre- and the post-measurements and <em>N</em><sub>adjusted</sub> is the effective sample size when using ANCOVA</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">crossing</span>(<span class="at">n =</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>),</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">rho =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.01</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">design_factor =</span> <span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n_ancova =</span> design_factor <span class="sc">*</span> n,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">n_group =</span> <span class="fu">factor</span>(n)) <span class="sc">|&gt;</span>  </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n_group =</span> <span class="fu">fct_rev</span>(n_group)) <span class="sc">|&gt;</span>  </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> rho, <span class="at">y =</span> n_ancova, <span class="at">color =</span> n_group, <span class="at">group =</span> n)) <span class="sc">+</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="fu">expression</span>(<span class="fu">italic</span>(N)<span class="sc">~</span>required<span class="sc">~</span>by<span class="sc">~</span>ANOVA),</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>                        <span class="at">option =</span> <span class="st">&quot;D&quot;</span>, <span class="at">end =</span> .<span class="dv">75</span>) <span class="sc">+</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="fu">expression</span>(rho),</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>                     <span class="at">expand =</span> <span class="fu">expansion</span>(<span class="at">mult =</span> <span class="dv">0</span>),</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>                     <span class="at">breaks =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">5</span> <span class="sc">/</span> <span class="dv">5</span>,</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>                     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;0&quot;</span>, <span class="st">&quot;.2&quot;</span>, <span class="st">&quot;.4&quot;</span>, <span class="st">&quot;.6&quot;</span>, <span class="st">&quot;.8&quot;</span>, <span class="st">&quot;1&quot;</span>)) <span class="sc">+</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="fu">expression</span>(<span class="fu">italic</span>(N)<span class="sc">~</span>required<span class="sc">~</span>by<span class="sc">~</span>ANCOVA),</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>                     <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">210</span>),</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>                     <span class="at">expand =</span> <span class="fu">expansion</span>(<span class="at">add =</span> <span class="dv">0</span>))</span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure6" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure6-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6: Relationship between sample size required by ANCOVA and ANOVA as a function of the correlation between pre- and post-measurements
</figcaption>
</figure>
</div>
</div>
</div>
<p>As illustrated in <a href="#fig-figure6" class="quarto-xref">Figure 6</a>, the higher the correlation, the smaller the sample size required by the ANCOVA model compared to the ANOVA model. For instance, assuming a correlation of rho = 0.7, the ANCOVA model will require approximately 102 participants to achieve the same power that would otherwise require 200 participants using a traditional ANOVA. The advantage of including baseline covariates is most pronounced when the correlation is high.</p>
</section>
<section id="adjust-for-multiple-comparisons" class="level2" data-number="2.5">
<h2 data-number="2.5"><span class="header-section-number">2.5</span> Adjust for multiple comparisons</h2>
<p>If researchers plan to adjust for multiple comparisons, the alpha level used in the a priori power analysis should also be adjusted. For example, suppose a researcher aims to test whether Intervention A is superior to Intervention B in improving heart rate, blood pressure, and cholesterol levels, and is willing to claim support for the hypothesis if any one of these three outcomes shows improvement. In this case, because multiple tests are being conducted, the overall Type I error rate would be inflated if the nominal alpha (e.g., 0.05) were applied to each test individually. Adjusting the alpha level (e.g., using a Bonferroni correction or other multiple-comparison procedures) ensures that the family-wise error rate remains controlled and should be incorporated into both study planning and power calculations.</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>adj <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">d =</span> <span class="fl">0.2</span>, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fl">0.8</span>, </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sig.level =</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">3</span>, <span class="co"># assuming three multiple comparisons</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;two.sample&quot;</span>, </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>adj</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     Two-sample t test power calculation 

              n = 442.0804
              d = 0.2
      sig.level = 0.01666667
          power = 0.8
    alternative = greater

NOTE: n is number in *each* group</code></pre>
</div>
</div>
<p>This study design would require a sample size of 443 to achieve a power of 0.8 with an alpha of <strong>0.0166667</strong>.</p>
<p>However, if the researcher did not adjust the alpha level in the a priori power analysis, the required sample size would be:</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>no_adj <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">d =</span> <span class="fl">0.2</span>, </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fl">0.8</span>, </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sig.level =</span> <span class="fl">0.05</span>, </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;two.sample&quot;</span>, </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>no_adj</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     Two-sample t test power calculation 

              n = 309.8065
              d = 0.2
      sig.level = 0.05
          power = 0.8
    alternative = greater

NOTE: n is number in *each* group</code></pre>
</div>
</div>
<p>With 310 participants per group, <em>d</em> = 0.2, and alpha = 0.05, this design achieves 80% power without correction.</p>
<p>But if we apply the adjusted-alpha level to this smaller sample size:</p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.t.test</span>(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">d =</span> <span class="fl">0.2</span>, </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">310</span>, </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sig.level =</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">3</span>, <span class="co"># assuming three multiple comparisons</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;two.sample&quot;</span>, </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     Two-sample t test power calculation 

              n = 310
              d = 0.2
      sig.level = 0.01666667
          power = 0.6395933
    alternative = greater

NOTE: n is number in *each* group</code></pre>
</div>
</div>
<p>This shows that the study design would be underpowered once multiple-comparison correction is applied post hoc.</p>
</section>
</section>
<section id="sec-es-justification" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Effect size justification</h1>
<p>An a priori power analysis is a method researchers can use to ensure their studies are designed with high power to reliably detect an effect size of interest. But what exactly is <em>the effect size of interest</em>? The effect size refers to the magnitude of a phenomenon or intervention—essentially, how big the effect is. The effect size of interest, then, is the specific quantity that researchers aim to detect and it central to the research question and purpose of the study. The effect size of interest might represent, for example, a correlation between two variables (e.g., stress and exercise), a difference between two groups, or an interaction effect. To design an informative study is essential that researchers carefully consider which effect sizes are interesting. It can be informative to compute the critical effect size for a study design <span class="citation" data-cites="perugini_critical_es_2025">(<a href="#ref-perugini_critical_es_2025" role="doc-biblioref">A. Perugini et al. 2025</a>)</span>. The critical effect size (<em>d</em><sub>crit</sub>) is the minimal effect size that can reach statistical significance given a sample size, test and α. For an unpaired <em>t</em>-test, <em>d<sub>crit</sub></em> can be calculated as follows:</p>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">50</span>              <span class="co"># total sample size</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>type <span class="ot">&lt;-</span> <span class="st">&quot;two.sided&quot;</span>  <span class="co"># type of test</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>ci <span class="ot">&lt;-</span> <span class="fl">0.95</span>           <span class="co"># confidence interval</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate critical effect size</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>dc <span class="ot">&lt;-</span> <span class="fu">critical_t2s</span>(<span class="at">n1 =</span> N<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">n2 =</span> N<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>                   <span class="at">var.equal =</span> <span class="cn">TRUE</span>,  </span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>                   <span class="at">hypothesis =</span> type, </span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>                   <span class="at">conf.level =</span> ci) </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in crit_from_t_t2s(t = t, n1 = n1, n2 = n2, se = se, conf.level =
conf.level, : When t is NULL, d cannot be computed, returning NA</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in crit_from_t_t2s(t = t, n1 = n1, n2 = n2, se = se, conf.level =
conf.level, : When se = NULL bc cannot be computed, returning NA!</code></pre>
</div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>ci</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.95</code></pre>
</div>
</div>
<p>This means that a study employing a two-group design with an N of 50 (25 per group) can only yield a significant result if the observed effect size is equal to or larger than <em>d<sub>crit</sub></em> = 0.57. It can therefore be informative to ask yourself whether <em>d<sub>crit</sub></em> for a study desing falls within the range of effect sizes that can be realistically expected. Below we briefly discuss common approaches for justifying effect sizes of interest and highlight their limitations. For a more comprehensive overview, readers are encouraged to consult <span class="citation" data-cites="lakens_justification_2022">Daniël Lakens (<a href="#ref-lakens_justification_2022" role="doc-biblioref">2022a</a>)</span>, which provides detailed guidance on best practices for effect size justification in a priori power analyses.</p>
<section id="smallest-effect-size-of-interest-sesoi" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Smallest effect size of interest (SESOI)</h2>
<p>The SESOI represents the smallest effect size that researchers consider practically or theoretically relevant. In clinical contexts, this concept is often referred to as the Minimal Clinical Importance Difference (MCID; <span class="citation" data-cites="cook_mcid_2008">Cook (<a href="#ref-cook_mcid_2008" role="doc-biblioref">2008</a>)</span>), which represents the smallest change in a treatment outcome that a patient or clinician would regard as meaningful enough to warrant a change in clinical management or treatments. In essence, the SESOI sets a lower bound on what effects are considered relevant. Effects smaller than the SESOI are viewed as too small to be meaningful, either practically or theoretically, and are therefore considered unimportant. Readers are referred to <span class="citation" data-cites="anvari_sesoi">Anvari and Lakens (<a href="#ref-anvari_sesoi" role="doc-biblioref">2021</a>)</span> for a comprehensive overview of different approaches to set the SESOI. Basing an a priori power analysis on the SESOI is considered best practice <span class="citation" data-cites="lakens_justification_2022">(<a href="#ref-lakens_justification_2022" role="doc-biblioref">Daniël Lakens 2022a</a>)</span>, as it allows researchers to design more informative studies <span class="citation" data-cites="lakens_equivalence_2017 murphy_minimum-effect-test_1999 riesthuis_simulations">(<a href="#ref-lakens_equivalence_2017" role="doc-biblioref">Daniël Lakens 2017</a>; <a href="#ref-murphy_minimum-effect-test_1999" role="doc-biblioref">Murphy and Myors 1999</a>; <a href="#ref-riesthuis_simulations" role="doc-biblioref">Riesthuis 2024</a>)</span>. That is, setting the SESOI enables researchers to design studies that can (a) test whether an effect size is statistically smaller that the SESOI, and therefore practically equivalent to 0 (using an equivalence test; <span class="citation" data-cites="lakens_equivalence_2017">Daniël Lakens (<a href="#ref-lakens_equivalence_2017" role="doc-biblioref">2017</a>)</span>); and (b) test whether an effect size is statistically larger than the SESOI and thus meaningful (using a minimum-effect test; <span class="citation" data-cites="murphy_minimum-effect-test_1999">Murphy and Myors (<a href="#ref-murphy_minimum-effect-test_1999" role="doc-biblioref">1999</a>)</span>]. Although basing a priori power analyses on the SESOI is methodologically considered best practice, defining the SESOI is a complex task that requires domain knowledge and dedicated research. As a result, this approach is not always a feasible approach. Consequently, researchers often rely on alternative approaches that come with important limitations.</p>
</section>
<section id="expected-effect-sizes" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Expected effect sizes</h2>
<p>When setting the SESOI is not possible, researchers often base their a priori power analysis on an expected effect size. Because the true effect size is generally unknown, researchers need to make educated guesses about the true effect. For that, they typically use:</p>
<section id="an-estimate-from-a-previous-study" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1"><span class="header-section-number">3.2.1</span> An estimate from a previous study</h3>
<p>Researchers often base their a priori power analysis on an effect size reported in a previous study. It is worth highlighting that in most empirical studies, researchers collect data from a sample of a broader population—such as university students in a country, patients with Alzheimer’s disease or pregnant women— because it is rarely feasible to collect data from the entire population. As a result, effect sizes calculated from samples are merely estimates of the true population effect and are subject to random variation. For example, if the true effect size is <em>d</em> = 0.2, a researcher might observe a larger or smaller effect in their study just by purely chance. This sampling variability can lead to over- or underestimation of the true effect size.</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>) </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># total sample size</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>smd <span class="ot">&lt;-</span> <span class="fl">0.3</span> <span class="co"># standardized mean difference</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data for a two-group study design</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> smd, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>inttervention <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> smd, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate effect size</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>observed_smd <span class="ot">&lt;-</span> <span class="fu">escalc</span>(</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">m1i =</span> <span class="fu">mean</span>(control), <span class="at">sd1i =</span> <span class="fu">sd</span>(control), <span class="at">n1i =</span> N<span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">m2i =</span> <span class="fu">mean</span>(intervention), <span class="at">sd2i =</span> <span class="fu">sd</span>(intervention), <span class="at">n2i =</span> N<span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> <span class="st">&quot;SMD&quot;</span>) </span></code></pre></div>
</div>
<p>In this simulated study, the observed effect size = 0.13 which overestimates the true effect size <em>d</em> = 0.3. This illustrates how random variation might result in an overestimated or underestimated estimate of the true effect size.<br />
<br />
Another reason researchers should be careful when using an effect size from a previous study is the presence of selection bias in the published literature. Two sources of selection bias are (a) the preference of editors, reviewers and researchers to prefer studies yielding significant <em>p</em>-values in support of the tested hypothesis <span class="citation" data-cites="scheel_excessive">(e.g., <a href="#ref-scheel_excessive" role="doc-biblioref">Scheel, Schijen, and Lakens 2021</a>)</span> and (b) questionable research practices that exploit flexibility in data analysis to render non-significant p-values significant <span class="citation" data-cites="bakker_rules_game stefan_big_little_lies">(e.g., <a href="#ref-bakker_rules_game" role="doc-biblioref">Bakker, van Dijk, and Wicherts 2012</a>; <a href="#ref-stefan_big_little_lies" role="doc-biblioref">Stefan and Schönbrodt 2023</a>)</span>. Selection bias leads to inflated effect sizes, especially in the presence of studies with underpowered designs. This phenomenon can be intuitively illustrated using the concept of critical effect size (<em>d</em><sub>crit</sub>).</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning in crit_from_t_t2s(t = t, n1 = n1, n2 = n2, se = se, conf.level =
conf.level, : When var.equal = FALSE the critical value calculated from t
assume sd1 = sd2!</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in crit_from_t_t2s(t = t, n1 = n1, n2 = n2, se = se, conf.level =
conf.level, : When t is NULL, d cannot be computed, returning NA</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in crit_from_t_t2s(t = t, n1 = n1, n2 = n2, se = se, conf.level =
conf.level, : When se = NULL bc cannot be computed, returning NA!</code></pre>
</div>
</div>
<p>Assuming a study employing a two-group design with an N of 50 (25 per group), <em>d<sub>crit</sub></em> is equal to 0.5686934. Assuming that the true effect size is smaller than this critical value, and publication bias is present, studies that happen to overestimate the true effect size are more likely to be published. As a result, published effect sizes are more likely to be inflated estimates of the true effect. This bias is illustrated in Figure 7: although the true effect size is 0.3, effect sizes larger than 0.5686934 are more likely to be published, leading to a biased literature <span class="citation" data-cites="hagger_multilab_2016 ciria_umbrella_review kvarven_2020">(e.g., <a href="#ref-hagger_multilab_2016" role="doc-biblioref">Hagger et al. 2016</a>; <a href="#ref-ciria_umbrella_review" role="doc-biblioref">Ciria et al. 2023</a>; <a href="#ref-kvarven_2020" role="doc-biblioref">Kvarven, Strømland, and Johannesson 2020</a>)</span>. If researchers use such inflated effect sizes in a priori power analysis, the resulting analysis will underestimate the required sample size, increasing the risk that the new study will also be under-powered <span class="citation" data-cites="anderson_sample_planning">(<a href="#ref-anderson_sample_planning" role="doc-biblioref">Anderson, Kelley, and Maxwell 2017</a>)</span>. Unless the study is a Registered Report, researchers should be cautious when relying on reported effect sizes from previous studies and are encouraged to use conservative or adjusted-bias effect size estimates (see next section).</p>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>) </span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>smd <span class="ot">&lt;-</span> <span class="fl">0.3</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>n_sim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate a distribution of effect sizes</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>effect_sizes <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_sim, <span class="at">mean =</span> smd, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a density object</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>density_obj <span class="ot">&lt;-</span> <span class="fu">density</span>(effect_sizes)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame from the density object</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> density_obj<span class="sc">$</span>x, <span class="at">y =</span> density_obj<span class="sc">$</span>y)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new column to color the area</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>color <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(df<span class="sc">$</span>x <span class="sc">&gt;</span> dc<span class="sc">$</span>dc, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Load ggplot2 for plotting</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the density with shaded areas</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df, x <span class="sc">&lt;=</span> dc<span class="sc">$</span>dc), <span class="fu">aes</span>(<span class="at">fill =</span> color), <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df, x <span class="sc">&gt;</span> dc<span class="sc">$</span>dc), <span class="fu">aes</span>(<span class="at">fill =</span> color), <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> dc<span class="sc">$</span>dc, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="fu">expression</span>(Effect<span class="sc">~</span>size<span class="sc">~</span><span class="fu">italic</span>(d))) <span class="sc">+</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="sc">+</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_identity</span>() <span class="sc">+</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-figure7" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure7-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 7: Distribution of effect sizes d when true effect is 0.2. The red area represents effect sizes that exceed the critical value and are more likely to be published, while the blue area represents smaller, non-significant effect sizes that are less likely to be published. The dashed vertical line indicates the critical effect size.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="an-estimate-from-a-pilot-study" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2"><span class="header-section-number">3.2.2</span> An estimate from a pilot study</h3>
<p>It is not uncommon that researchers conduct a pilot study to obtain an estimate of the true effect size which is then used to conduct an a priori power analysis. However, as shown by <span class="citation" data-cites="lakens_followup_bias">Albers and Lakens (<a href="#ref-lakens_followup_bias" role="doc-biblioref">2018</a>)</span>, this practice leads to substantially under-powered studies in most realistic situations. Researchers who base their a priori power analyses on effect size estimates observed in pilot studies will unknowingly design on average underpowered studies, as long as they do not take bias in the estimated effect sizes and follow-up bias into account. The diference between the desired and achieved power can be especially worrying when the sample size of the pilot study and/or the population effect size is small.</p>
</section>
<section id="an-estimate-from-a-meta-analysis" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3"><span class="header-section-number">3.2.3</span> An estimate from a meta-analysis</h3>
<p>Another source for informing a priori power analyses are meta-analyses. However, they may suffer from the same limitations as individual studies. If the published literature suffers from studies with under-powered designs and selection bias, published effect sizes may end up in meta-analyses leading to inflated meta-analytic effect sizes <span class="citation" data-cites="hagger_multilab_2016 ciria_umbrella_review kvarven_2020">(e.g., <a href="#ref-hagger_multilab_2016" role="doc-biblioref">Hagger et al. 2016</a>; <a href="#ref-ciria_umbrella_review" role="doc-biblioref">Ciria et al. 2023</a>; <a href="#ref-kvarven_2020" role="doc-biblioref">Kvarven, Strømland, and Johannesson 2020</a>)</span>. In this case, researchers should select bias-adjusted meta-analytic effect sizes to obtain a more conservative effect size estimate for their a priori power analyses.</p>
</section>
</section>
<section id="effect-size-thresholds" class="level2" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Effect size thresholds</h2>
<section id="cohens-d-thresholds" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1"><span class="header-section-number">3.3.1</span> Cohen’s <em>d</em> thresholds</h3>
<p>Researchers sometimes base their a priori power analyses on Cohen’s <em>d</em> thresholds-typically interpreting <em>d</em> &lt; 0.2 as a small effect, 0.2 &lt; <em>d</em> &lt; 0.5 as medium, and <em>d</em> &gt; 0.5 as large. Even when you open G*Power, a ‘medium’ effect size is the default option. However, Cohen’s <em>d</em> thresholds should not be used in a priori power analyses. Cohen originally proposed them to describe typical effect sizes observed in social psychology. Applying these benchmarks to other scientific fields ignores the ‘research context’ including the populations from which participants were drawn, research designs, intervention or experimental manipulation. As a result, selecting am effect size based on Cohen’s <em>d</em> benchmarks may lead to a situation where the selected effect size does not reflect the true effect size. Using an inappropriate effect size can lead to under-powered study designs (when the true effect size is smaller) or over-powered study designs (if the true effect size is larger), both of which pose methodological and ethical concerns.</p>
</section>
<section id="field-specific-thresholds" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2"><span class="header-section-number">3.3.2</span> Field-specific thresholds</h3>
<p>In other occasions, researchers might use Cohen’s <em>d</em> thresholds derived from the distirbution of effect sizes within a field. While this approach appears more tailored than using Cohen’s <em>d</em> thresholds, it should still be avoided. The studies used to calculate these field-specific distributions may differ substantially from the planned study in terms of design, population, or measurement tools. Additionally, published effect sizes might be inflated due to selection bias and studies with under-powered designs.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>If researchers cannot justify an effect size of interest, they should not be compelled to conduct an a priori power analysis. Designing a high-powered study requires careful groundwork and a solid understanding of the underlying phenomenon <span class="citation" data-cites="scheel_why_hypothesis">(<a href="#ref-scheel_why_hypothesis" role="doc-biblioref">Scheel et al. 2020</a>)</span>. Without this foundational knowledge, researchers may lack the theoretical understanding to specify a plausible effect size. In such cases, sample size justifications based on sequential analysis might be more appropriate <span class="citation" data-cites="lakens_sequential_2014">(<a href="#ref-lakens_sequential_2014" role="doc-biblioref">Daniël Lakens 2014</a>)</span>.</p>
</div>
</div>
</section>
</section>
</section>
<section id="things-to-take-into-account-when-conducting-an-a-priori-power-analysis" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Things to take into account when conducting an a priori power analysis</h1>
<section id="adjusting-for-uncertainty-and-bias" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Adjusting for uncertainty and bias</h2>
<p>As previously discussed, researchers often use an effect size from a previous study as an estimate of the true effect size when conducting an a priori power analysis. However, caution is warranted for two main reasons: (1) due to random variation, the observed effect size in a study may differ from the true population effect size, specially in studies with small samples, and (2) selection bias can inflate reported effect sizes. Therefore, when selecting an effect size from a previous study, researchers should consider using a more conservative estimate that accounts for uncertainty and bias.</p>
<section id="safeguard-power-analysis" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1"><span class="header-section-number">4.1.1</span> Safeguard power analysis</h3>
<p>One method is what <span class="citation" data-cites="perugini_safeguard">M. Perugini, Gallucci, and Costantini (<a href="#ref-perugini_safeguard" role="doc-biblioref">2014</a>)</span> refer to as a <em>safeguard power analysis</em> which uses a more conservative effect size estimate to conduct the a priori power analysis. For example, researchers may select the lower bound of a two-sided 60% CI, which is equivalent to a one-sided 80% CI. Suppose that a researchers selects an effect size <em>d</em> = 0.5 reported in a previous study with an N of 50 (25 per group) and she suspects that the true effect size is smaller. The package <em><code>MBESS</code></em> can be used to estimate the lower bound of the 60% CI for the reported effect size.</p>
<div class="cell">
<div class="sourceCode" id="cb35"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>cons_smd <span class="ot">&lt;-</span> <span class="fu">ci.smd</span>(<span class="at">smd =</span> smd, <span class="at">n.1 =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">n.2 =</span> N<span class="sc">/</span><span class="dv">2</span>, <span class="at">conf.level =</span> .<span class="dv">60</span>)</span></code></pre></div>
</div>
<p>The lower bound of the 60% CI corresponds to an effect size <em>d</em> of 0.06 which could then be used in an a priori power analysis.</p>
</section>
<section id="bias-adjusted-effect-size-estimate" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2"><span class="header-section-number">4.1.2</span> Bias-adjusted effect size estimate</h3>
<p>Another method to account for uncertainty and potential inflation of effect size estimates reported in the literature is to adjust the effect size using the package <em><code>BUCSS</code></em> <span class="citation" data-cites="bucss_software">(<a href="#ref-bucss_software" role="doc-biblioref">Anderson and Kelley 2016</a>)</span>. This approach allows researchers to correct for uncertainty and bias when planning their sample size. For a detailed discussion on how to adjust inflated effect size estimates using the package <code>BUCSS</code> , readers are referred to <span class="citation" data-cites="anderson_sample_planning">Anderson, Kelley, and Maxwell (<a href="#ref-anderson_sample_planning" role="doc-biblioref">2017</a>)</span> and the <a href="https://cran.r-project.org/web/packages/BUCSS/BUCSS.pdf">package documentation</a>. Below we demonstrate how to use the BUCSS package to account for publication bias and uncertainty in the context of an unpaired <em>t</em>-tests and a two-way mixed ANOVA with one between-subject and one within-subject factor. For additional supported tests, consult <a href="https://cran.r-project.org/web/packages/BUCSS/BUCSS.pdf">package documentation</a>.</p>
<p>Any function requires the reported test statistic and sample size from a previous study, along with several key arguments:</p>
<ul>
<li><p>alpha.priori: the assumed statistical significance necessary for publishing in the field. To assume no publication bias and correct only for uncertainty, a value of 1 can be entered</p></li>
<li><p>alpha.planned: alpha level of the planned study</p></li>
<li><p>assurance: the long run proportion of times that the planned study power will reach or surpass desired level of power</p></li>
<li><p>power: desired level of power for the planned study.</p></li>
</ul>
<p>Suppose a researcher plans to use an effect size reported in a previous study to conduct an a priori power analysis for their study. However, she suspects that the effect size is much smaller and that this research line suffers from publication bias and studies with under-powered designs, which result in inflated effect sizes in the published literature. To address this, she can use BUCSS to estimate the necessary sample size to achieve the desired level of power while correcting for bias and uncertainty.</p>
<p>Example 1: unpaired <em>t</em>-test</p>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ss.power.it</span>(<span class="at">t.observed =</span> <span class="dv">3</span>, </span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">N =</span> <span class="dv">30</span>, </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">alpha.prior =</span> <span class="fl">0.05</span>, </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">alpha.planned =</span> <span class="fl">0.05</span>,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">assurance =</span> <span class="fl">0.8</span>, </span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">power =</span> <span class="fl">0.8</span>, </span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">step =</span> <span class="fl">0.001</span>)[[<span class="dv">1</span>]] <span class="co"># only returns sample size</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 131</code></pre>
</div>
</div>
<p>Example 2: a two-way mixed ANOVA with one between-subject and one within-subject factor</p>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ss.power.spa</span>(<span class="at">F.observed =</span> <span class="dv">8</span>, </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">N =</span> <span class="dv">40</span>, </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">levels.between =</span> <span class="dv">2</span>, </span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">levels.within =</span> <span class="dv">2</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">effect =</span> <span class="st">&quot;interaction&quot;</span>, </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha.prior =</span> <span class="fl">0.05</span>, </span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha.planned =</span> <span class="fl">0.05</span>, </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">assurance =</span> <span class="fl">0.8</span>,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">power =</span> <span class="fl">0.8</span>, </span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">step=</span> <span class="fl">0.001</span>)[[<span class="dv">1</span>]] <span class="co"># only returns sample size</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 467</code></pre>
</div>
</div>
<div class="callout-message">
<p><strong>Note</strong></p>
<p>Often the corrected noncentrality parameter for a given level of assurance will be estimated to be zero. This is an indication that, at the desired level of assurance, the previous study’s effect cannot be accurately estimated due to high levels of uncertainty and bias. When this occurs, it is not possible to calculate a sample size under the current specifications. In such situations, researchers may need to adjust the assurance level and/or reconsider the assumed publication bias.</p>
</div>
</section>
</section>
<section id="study-context" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Study context</h2>
<p>When selecting an effect size from a previous study to inform an a priori power analysis, researchers should ensure that both studies are comparable in terms of context <span class="citation" data-cites="lakens_sample_justification">(<a href="#ref-lakens_sample_justification" role="doc-biblioref">Daniël Lakens 2022b</a>)</span>. This involves evaluating key elements PICOS—Population, Intervention, Comparator, Outcome and Study design—. For instance, populations with higher variability (i.e., larger SD) for a given outcome can yield smaller effect sizes, even when the mean difference is the same. Similarly, an intervention may produce different effect sizes across populations if it has a greater impact on the primary outcome in one population than in the other. Furthermore, the intervention itself must be comparable in terms of intensity and implementation. A stronger manipulation may produce larger effects. Similarly, the comparator—the group or condition against which the intervention is compared, which might be a placebo, a standard procedure or no intervention—can also influence the effect size estimate. If the primary outcome differs in operationalization or measurement, the effect sizes might not directly be comparable.</p>
<p>A final aspect to consider is the study design. To be able to select an effect size from a previous study, both study designs need to be similar. Researchers often conduct studies to test whether an effect is moderated by a second factor that suppresses, exacerbates or reverses the effect caused by a first factor– what is known as an interaction effect–. In our experience, many researchers assume it is reasonable to select an effect size from a previous study that employed a simple design (i.e., a paired-sample design or an unpaired-sample design)—note this also applies to factorial design with one of the factors with two levels (df1 = 1)—to conduct an a priori power analysis for an interaction effect. However, whether the selected effect size is a good estimate of the interaction effect depends on the type of interaction or pattern of means that researchers expect to observe­. Broadly speaking, there are three types of interactions: ordinal, disordinal or attenuated interaction (Figure 8). Readers are referred to <span class="citation" data-cites="sommet_interaction">Sommet et al. (<a href="#ref-sommet_interaction" role="doc-biblioref">2023</a>)</span> for a discussion about how different types of interactions affect power. To understand how the patterns of means affect the interaction effect size, it helps to conceive interactions as a “difference of differences” <span class="citation" data-cites="sommet_interaction langenberg_tutorial">(<a href="#ref-sommet_interaction" role="doc-biblioref">Sommet et al. 2023</a>; <a href="#ref-langenberg_tutorial" role="doc-biblioref">Langenberg et al. 2023</a>)</span>. Under this approach, the calculation of a two-way interaction corresponds to the difference between a) the difference between the two levels of a factor at one level of the second factor and b) the difference between the two levels of a factor at the second level of the second factor. The advantage of this approach is that researchers can conduct an a priori power analysis for an interaction effect using a <em>t-</em>test and solely requires the specification of an expected effect size in terms of Cohen’s <em>d.</em> For a 2 x 2 between-subject design, the interaction effect can be calculated as follows <span class="citation" data-cites="sommet_interaction">(<a href="#ref-sommet_interaction" role="doc-biblioref">Sommet et al. 2023</a>)</span>:</p>
<p><span class="math display">\[
d_{\text{int}} = \frac{(E_1 - C_1)}{\text{SD}_{\text{pooled}}} - \frac{(E_2 - C_2)}{\text{SD}_{\text{pooled}}}= \frac{(E_1 - C_1) - (E_2 - C_2)}{2 \times \text{SD}_{\text{pooled}}}
\]</span></p>
<p>Where E and C refer to the experimental and control group respectively, and the subscripted numbers refer to the levels of the second factor. Thus, <em>d<sub>int</sub></em> boils down to computing the difference between two standardised mean differences (<em>d<sub>s</sub></em>) from the two main effects for which an a priori power analysis can be conducted in the framework of an unpaired <em>t</em>-test. To see how the pattern of means affects the interaction effect size, imagine we wish to test whether the effect of a supplement is moderated by the intake time (i.e., morning vs. afternoon) using a 2 x 2 between-subject design. Specifically, we expect that taking the supplement in the evening will knock out the effect of taking the supplement in the morning—what is known as an ordinal interaction (Figure 8b)—. To conduct the a priori power analysis for this interaction effect, we rely on a previous study based on a between-subject design with two groups that found that the supplement of interest improved cycling time to exhaustion in comparison to a placebo. Assuming an equal SD of 2, the improvement in time to exhaustion would correspond to a Cohen’s <em>d<sub>s</sub></em>= 0.5 (1 – 0 / 2 = 0.5; Figure 8a).</p>
<p>Now imagine that a researcher uses this Cohen’s <em>d<sub>s</sub></em> as an estimate of the hypothesized ordinal interaction to conduct the a priori power analysis. Plugging an effect size of <em>d<sub>s</sub></em> = 0.5, a type I error of a = 0.05, and a desired power of 0.8 into G*Power yields an N of 128 for a two-sided unpaired <em>t</em>-test, or 32 participants for each of the four groups in our 2 x 2 factorial design. However, this a priori power analysis would be invalid because the chosen effect size does not correspond to the hypothesized ordinal interaction. For the hypothesized ordinal interaction (<a href="#fig-figure1" class="quarto-xref">Figure 1</a> b), the pattern of means would correspond to a <em>d<sub>int</sub></em> = 0.25 ((1 – 0) – (0 – 0) / (2 x 2) = 0.25). Plugging an effect size of <em>d<sub>int</sub></em> = 0.25, a type I error = 0.05, and a desired level of statistical power to 0.8 into G*Power yields an N of 506 for a two-sided unpaired <em>t</em>-test, or about 127 participants per group. For a reverse interaction ( <a href="#fig-figure1" class="quarto-xref">Figure 1</a> c), the pattern of means would correspond to a <em>d<sub>int</sub></em> = 0.5 ((1 – 0) – (0 – 1) / (2 x 2) = 0.5). Thus, the selected effect size (<em>d<sub>s</sub></em> = 0.5) used in our a priori power analysis would be clearly invalid and only appropriate in the case that we were expecting a reverse interaction. Lastly, for an attenuated interaction (<a href="#fig-figure1" class="quarto-xref">Figure 1</a> d), the pattern of means would correspond to a <em>d<sub>int</sub></em> = 0.1 ((1 – 0) – (0.6 – 0) / (2 x 2) = 0.1). Plugging an effect size of <em>d<sub>int</sub></em> = 0.1, a type I error of a = 0.05, and power to 0.8 into G*Power for a two-sided unpaired <em>t</em>-test yields an N of 3142, or 786 participants per group. Using the wrong estimate of the interaction effect has dire consequences for the sample size required to find the interaction.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure8" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure8-1.png" class="img-fluid" width="1536" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 8: Illustration of different types of interactions in two-factor design. (a) = simple effect. (b) ordinal or fully attenuated interaction. (c) reverse interaction. (d) attenuated interaction.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The same approach applies to within-subject factorial designs. The key difference is that researchers need to know the correlation between measurements/conditions to estimate the covariance matrix required to compute the effect size. For a detailed tutorial, see <span class="citation" data-cites="langenberg_tutorial">Langenberg et al. (<a href="#ref-langenberg_tutorial" role="doc-biblioref">2023</a>)</span>.</p>
</section>
</section>
<section id="sec-power-analysis" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conducting an a priori power analysis</h1>
<p>Statistical software offers options for power analyses for some statistical tests, but not for all tests. For instance, G*Power allows researchers to perform power analyses for ANOVA designs but not for pairwise comparisons. In such cases, a simulation-based approach to power analysis becomes necessary. Another key advantage of simulation-based approaches is their flexibility. They allow researchers to explore how different assumptions (e.g., size of the effect, correlation between measurements) or analytic decisions (e.g., include or not a covariate) affect power. This makes simulation especially useful in complex study designs where analytical formulas are limited or unavailable.</p>
<p>To estimate the power for factorial designs, researchers can use the package <code>Superpower</code> to set up the factorial design using <code>ANOVA_design()</code> and perform the simulations using <code>ANOVA_power()</code> analyses for main and interaction effects as well as planned pairwise comparisons. A comprehensive tutorial on using <code>Superpower</code> package can be found in <a href="https://aaroncaldwell.us/SuperpowerBook/">Power Analysis with Superpower</a>.</p>
<p>A more flexible simulation-based approach involves using <code>faux::sim_design()</code> <span class="citation" data-cites="debruine_faux">(<a href="#ref-debruine_faux" role="doc-biblioref">L. DeBruine 2023</a>)</span> to simulate data and applying the relevant test to estimate power. This approach is particularly flexible, as it enables researchers to simulate data not only for basic (i.e., paired- and unpaired-sample designs) and factorial designs, but also for more complex designs such as multilevel models. For a comprehensive tutorial on using <code>faux</code> package, readers are referred to <a href="https://debruine.github.io/faux/index.html" class="uri">https://debruine.github.io/faux/index.html</a>. For a gentle introduction to conducting a power analysis using simulations, readers are also referred to <a href="https://nickch-k.github.io/EconometricsSlides/Week_08/Power_Simulations.html">Nick’s post</a> and <a href="https://lmu-osc.github.io/Simulations-for-Advanced-Power-Analyses/LM1.html">LMU Open Science Center</a>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The basic steps of the more flexible form of simulation-based approach are:</p>
<ul>
<li><p>Simulate data with the desired properties (e.g., group means and standard deviations).</p></li>
<li><p>Perform the planned statistical test on the simulated data.</p></li>
<li><p>Extract the resulting <em>p</em>-value.</p></li>
<li><p>Repeat this process many times (e.g., 1,000 simulations).</p></li>
<li><p>Store the results.</p></li>
<li><p>Calculate power as the proportion of <em>p</em>-values that fall below the alpha level.</p></li>
</ul>
</div>
</div>
<p>In this section we demonstrate how to conduct a priori power analyses using R packages and simulation-based approaches. This section begins with simple research designs, including paired- and unpaired-sample designs, moves on to factorial designs, then briefly covers equivalence tests and concludes with simple multilevel models. For readers interested in a hands-on introduction using JAMOVI, we recommend <a href="https://open.lnu.se/index.php/metapsychology/article/view/3078">Power to the People: A Beginner’s Tutorial to Power Analysis using jamovi</a> <span class="citation" data-cites="bartlett_jamovi">(<a href="#ref-bartlett_jamovi" role="doc-biblioref">Bartlett and Charles 2022</a>)</span>. For readers interested in a hands-on introduction using G*Power, we recommend <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=https://files.osf.io/v1/resources/pcfvj/providers/osfstorage/5dcea84d5b97bd000e57aba0%3Faction%3Ddownload%26version%3D1%26direct&amp;ved=2ahUKEwjtgZuoiPmNAxVMhv0HHV1ADNcQFnoECBsQAQ&amp;usg=AOvVaw2CLKMTGddzS9qyMWaGJMmA">Introduction to sample size calculation using G*Power</a>.</p>
<section id="paired-sample-design" class="level2" data-number="5.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Paired-sample design</h2>
<p>In a paired-sample design or a pre-post design is used when researchers collect data from the same participants at two time points and aim to test whether there is a statistically significant difference between those time points. Paired-sample designs are typically analysed using a paired <em>t-</em>test.</p>
<p>Suppose a researcher hypothesizes that the difference in reaction time between morning and evening will correspond to a Cohen’s <em>d<sub>rm</sub></em> of 0.2. The researcher plans to collect data from the same participants at both time points.</p>
<section id="using-pwr.t.test" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1"><span class="header-section-number">5.1.1</span> Using <code>pwr.t.test()</code></h3>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>pwr_paired <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">d =</span> <span class="fl">0.2</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>, <span class="at">power =</span> <span class="fl">0.8</span>,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;paired&quot;</span>, <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</div>
<p>For this study design, we would need a sample size of 199 to achieve 0.8.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the example, the researcher had a <strong>non-directional hypothesis</strong>, meaning they expected a difference between the interventions but did not specify the direction of the effect. For this reason, a <strong>two-sided paired <em>t</em>-test</strong> was appropriate.</p>
<p>However, if researchers have a <strong>directional hypothesis</strong>—for example, that <strong>intervention A is better than Intervention B</strong>—then a <strong>one-sided test</strong> should be used. One-sided tests are more powerful when the direction is correctly specified, but they should only be used when the research question and hypothesis clearly support a directional claim. Ideally this decision should be preregistered before data collection to prevent bias or post hoc justifications</p>
</div>
</div>
</section>
<section id="simulation-approach" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2"><span class="header-section-number">5.1.2</span> Simulation approach</h3>
<p>The overall idea is that we simulate many paired datasets, run a paired t-test for each, and estimate power as the proportion of times the null is rejected.</p>
<p>We need data for our example:</p>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)     <span class="co"># for reproducibility</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>             <span class="co"># sample size</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>morning <span class="ot">&lt;-</span> <span class="fl">0.2</span>       <span class="co"># morning mean</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>evening <span class="ot">&lt;-</span> <span class="fl">0.4</span>       <span class="co"># evening mean</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">1</span>              <span class="co"># common SD            </span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.5</span>           <span class="co"># correlation between measurements</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate one dataset</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;morning&quot;</span>, <span class="st">&quot;evening&quot;</span>)),</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(morning, evening),</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>      ) </span></code></pre></div>
</div>
<section id="using-t.test-or-lm" class="level4" data-number="5.1.2.1">
<h4 data-number="5.1.2.1"><span class="header-section-number">5.1.2.1</span> Using <code>t.test()</code> or <code>lm()</code></h4>
<p>Conduct a <code>t.test()</code> for paired data:</p>
<div class="cell">
<div class="sourceCode" id="cb42"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(df, <span class="fu">t.test</span>(morning, evening, <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>, <span class="at">paired =</span> <span class="cn">TRUE</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(estimate, statistic, p.value) <span class="sc">|&gt;</span> </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-0.29</td>
<td style="text-align: right;">-2.82</td>
<td style="text-align: right;">0.01</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Conducting a paired <em>t</em>-test using <code>t.test(paired = TRUE)</code> is statistically equivalent to fitting a linear model with <code>lm()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(evening <span class="sc">-</span> morning <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> df) <span class="sc">|&gt;</span> </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, estimate, statistic, p.value) <span class="sc">|&gt;</span> </span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">4</span>) <span class="sc">|&gt;</span> </span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">term</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.2873</td>
<td style="text-align: right;">2.8166</td>
<td style="text-align: right;">0.0059</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>This model includes an intercept, which estimates the mean difference between pre- and post-measurements. Testing whether this intercept differs from zero is identical to performing a paired <em>t</em>-test. In practice, both approaches yield the same results including achieving the same power, since they are based on the same model. This reflects a broader principle: correlations, <em>t</em>-tests, ANOVA and ANCOVA are all cases of linear models and can be expressed as simple or multiple regressions. For a clear exposition of this unified framework, see <a href="https://lindeloev.github.io/tests-as-linear/">Kristoffer Lindelov’s blog post</a>, <a href="https://niklasjohannes.github.io/power-workshop/content/07-categorical-predictors/07-slides.html">Niklas Johannes’ slides</a>, and <a href="https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iii/">Julian Quandt’s blog post</a>. Based on this approach, we can also conduct an a priori power analysis using simulations.</p>
</section>
<section id="simulation-using-t.test" class="level4" data-number="5.1.2.2">
<h4 data-number="5.1.2.2"><span class="header-section-number">5.1.2.2</span> Simulation using <code>t.test()</code></h4>
<p>Let’s define the parameters for the simulation:</p>
<div class="cell">
<div class="sourceCode" id="cb44"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                             <span class="co"># number of simulations</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>, <span class="dv">300</span>) <span class="co"># sample size per simulation</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">0</span>                                 <span class="co"># morning mean</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="fl">0.2</span>                               <span class="co"># evening mean</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>sd1 <span class="ot">&lt;-</span> <span class="dv">1</span>                                 <span class="co"># morning SD</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>sd2 <span class="ot">&lt;-</span> <span class="dv">1</span>                                 <span class="co"># evening SD</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.5</span>                               <span class="co"># correlation between measurements</span></span></code></pre></div>
</div>
<p>Let’s perform the simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ensure reproducibility</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)                         </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation function</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;morning&quot;</span>, <span class="st">&quot;evening&quot;</span>)),</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2),</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="fu">c</span>(sd1, sd2),</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    ) </span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>   <span class="fu">t.test</span>(df<span class="sc">$</span>morning, df<span class="sc">$</span>evening, <span class="at">paired =</span> <span class="cn">TRUE</span>, </span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)<span class="sc">$</span>p.value</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> <span class="fl">0.05</span>)</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Run function for all sample sizes</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> sample_size,</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span>  </span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.51</td>
</tr>
<tr class="even">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.69</td>
</tr>
<tr class="odd">
<td style="text-align: right;">200</td>
<td style="text-align: right;">0.81</td>
</tr>
<tr class="even">
<td style="text-align: right;">250</td>
<td style="text-align: right;">0.88</td>
</tr>
<tr class="odd">
<td style="text-align: right;">300</td>
<td style="text-align: right;">0.93</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
<section id="simulation-using-lm" class="level4" data-number="5.1.2.3">
<h4 data-number="5.1.2.3"><span class="header-section-number">5.1.2.3</span> Simulation using <code>lm()</code></h4>
<p>Let’s perform simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb46"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ensure reproducibility</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)                         </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation function</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(sim, {</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;morning&quot;</span>, <span class="st">&quot;evening&quot;</span>)),</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2),</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="fu">c</span>(sd1, sd2),</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    ) </span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lm</span>(df<span class="sc">$</span>morning <span class="sc">-</span> df<span class="sc">$</span>evening <span class="sc">~</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pull</span>(p.value)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> <span class="fl">0.05</span>)</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Run function using all sample sizes</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> sample_size,</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Return results</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.4</td>
</tr>
<tr class="even">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.8</td>
</tr>
<tr class="odd">
<td style="text-align: right;">200</td>
<td style="text-align: right;">0.2</td>
</tr>
<tr class="even">
<td style="text-align: right;">250</td>
<td style="text-align: right;">0.8</td>
</tr>
<tr class="odd">
<td style="text-align: right;">300</td>
<td style="text-align: right;">0.6</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
</section>
</section>
<section id="unpaired-sample-design" class="level2" data-number="5.2">
<h2 data-number="5.2"><span class="header-section-number">5.2</span> Unpaired-sample design</h2>
<p>In an unpaired-sample design or independent two-group design researchers collect data from two independent groups and aim to test whether there is a statistically significant difference between those two groups. This study design is typically analysed using an unpaired <em>t</em>-test.</p>
<p>Suppose a researcher hypothesizes that that drinking coffee in the morning affects shooting accuracy. The researcher expects the difference to correspond to a Cohen’s <em>d<sub>s</sub></em> of 0.2. To test this hypothesis, the researcher plans to randomly assign participants to two independent groups: one group that consumes coffee in the morning and one that does not.</p>
<section id="using-pwr.t.test-1" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1"><span class="header-section-number">5.2.1</span> Using <code>pwr.t.test()</code></h3>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>pwr_unpaired <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">d =</span> <span class="fl">0.2</span>, </span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">sig.level =</span> <span class="fl">0.05</span>, </span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fl">0.8</span>,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;two.sample&quot;</span>, </span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>pwr_unpaired</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     Two-sample t test power calculation 

              n = 393.4057
              d = 0.2
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

NOTE: n is number in *each* group</code></pre>
</div>
</div>
<p>For this study design, we would need a sample size of 394 to achieve 0.8.</p>
</section>
<section id="simulation-approach-1" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2"><span class="header-section-number">5.2.2</span> Simulation approach</h3>
<p>We need data:</p>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)     </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>             <span class="co"># sample size</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>intervention <span class="ot">&lt;-</span> <span class="fl">0.2</span>  <span class="co"># intervention mean</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>placebo <span class="ot">&lt;-</span> <span class="fl">0.4</span>       <span class="co"># placebo mean</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>sd1 <span class="ot">&lt;-</span> <span class="dv">1</span>             <span class="co"># intervention SD </span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>sd2 <span class="ot">&lt;-</span> <span class="dv">1</span>             <span class="co"># placebo SD</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate one dataset</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">&quot;intervention&quot;</span>, <span class="st">&quot;placebo&quot;</span>)),</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(intervention, placebo),</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="fu">c</span>(sd1, sd2),</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>      ) </span></code></pre></div>
</div>
<section id="using-t.test-or-lm-1" class="level4" data-number="5.2.2.1">
<h4 data-number="5.2.2.1"><span class="header-section-number">5.2.2.1</span> Using <code>t.test()</code> or <code>lm()</code>:</h4>
<p>Conduct a <code>t.test()</code> for unpaired data:</p>
<div class="cell">
<div class="sourceCode" id="cb50"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(y <span class="sc">~</span> group, df) <span class="sc">|&gt;</span> </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(estimate, statistic, p.value) <span class="sc">|&gt;</span> </span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-0.38</td>
<td style="text-align: right;">-2.71</td>
<td style="text-align: right;">0.01</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Conducting an unpaired <em>t</em>-test using <code>t.test()</code> is statistically equivalent to fitting a linear model using <code>lm()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y <span class="sc">~</span> group, <span class="at">data =</span> df) <span class="sc">|&gt;</span> </span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(term, estimate, statistic, p.value) <span class="sc">|&gt;</span> </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">term</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.10</td>
<td style="text-align: right;">1.04</td>
<td style="text-align: right;">0.30</td>
</tr>
<tr class="even">
<td style="text-align: left;">groupplacebo</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">2.71</td>
<td style="text-align: right;">0.01</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>The group variable is a categorical factor with two levels (i.e., placebo and intervention). This linear model estimates an intercept, which is the mean of the reference group (i.e., placebo) and a coefficient for the intervention group, which represents the mean difference between the two groups. In practice, both approaches yield the same results including achieving the same power, since they are based on the same model. Based on this approach, we can also conduct an a priori power analysis using simulations.</p>
</section>
<section id="simulation-using-t.test-1" class="level4" data-number="5.2.2.2">
<h4 data-number="5.2.2.2"><span class="header-section-number">5.2.2.2</span> Simulation using <code>t.test()</code></h4>
<p>Let’s define the parameters of the simulation:</p>
<div class="cell">
<div class="sourceCode" id="cb52"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                         <span class="co"># number of simulations</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>)  <span class="co"># total sample size</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">0</span>                              <span class="co"># intervention group mean</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="fl">0.2</span>                            <span class="co"># placebo group mean</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>sd1 <span class="ot">&lt;-</span> <span class="dv">1</span>                              <span class="co"># intervention group SD</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>sd2 <span class="ot">&lt;-</span> <span class="dv">1</span>                              <span class="co"># placebo group SD</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span></code></pre></div>
</div>
<p>Let’s perform the simulations using <code>t.test()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)                         </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation function</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">&quot;intervention&quot;</span>, <span class="st">&quot;placebo&quot;</span>)),</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2),</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="fu">c</span>(sd1, sd2),</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span>) <span class="sc">|&gt;</span> </span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">group =</span> <span class="fu">factor</span>(group, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;intervention&quot;</span>)))</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>     <span class="fu">t.test</span>(df<span class="sc">$</span>y[df<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&quot;placebo&quot;</span>], </span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>            df<span class="sc">$</span>y[df<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&quot;intervention&quot;</span>], </span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>            <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>, </span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>            <span class="at">paired =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>p.value</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> <span class="fl">0.05</span>)</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Run function for all sample sizes</span></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> sample_size,</span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.29</td>
</tr>
<tr class="even">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.43</td>
</tr>
<tr class="odd">
<td style="text-align: right;">200</td>
<td style="text-align: right;">0.51</td>
</tr>
<tr class="even">
<td style="text-align: right;">250</td>
<td style="text-align: right;">0.60</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
<section id="simulation-using-lm-1" class="level4" data-number="5.2.2.3">
<h4 data-number="5.2.2.3"><span class="header-section-number">5.2.2.3</span> Simulation using <code>lm()</code></h4>
<p>Let’s perform the simulations using <code>lm()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb54"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)                    </span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation function</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">&quot;intervention&quot;</span>, <span class="st">&quot;placebo&quot;</span>)),</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2),</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="fu">c</span>(sd1, sd2),</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span>) <span class="sc">|&gt;</span> </span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">group =</span> <span class="fu">factor</span>(group, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;intervention&quot;</span>)))</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lm</span>(y <span class="sc">~</span> group, <span class="at">data =</span> df) <span class="sc">|&gt;</span> </span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;groupintervention&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pull</span>(p.value)</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Run for all sample sizes</span></span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> sample_size,</span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant </span></span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.29</td>
</tr>
<tr class="even">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.43</td>
</tr>
<tr class="odd">
<td style="text-align: right;">200</td>
<td style="text-align: right;">0.51</td>
</tr>
<tr class="even">
<td style="text-align: right;">250</td>
<td style="text-align: right;">0.60</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
</section>
</section>
<section id="designs-with-more-than-two-levels" class="level2" data-number="5.3">
<h2 data-number="5.3"><span class="header-section-number">5.3</span> Designs with more than two levels</h2>
<p>A design with more than two levels means that the independent variable (factor) has three or more conditions or groups, rather than just two as is typical in a simple <em>t</em>-test. Research designs can also include two or more factors, in which case they are called factorial designs. Each factor can have two or more levels (conditions or groups). A common way to analyse designs with more than two levels is the Analysis of Variance (ANOVA).</p>
<p>When an <em>F</em>-test (i.e., ANOVA) yields a significant <em>p</em>-value, it indicates that there is a statistically significant difference among the condition/group means, but it does not reveal which specific conditions/groups differ from one other. When the null hypothesis is rejected in an <em>F</em>-test, researchers typically perform planned or post hoc pairwise comparisons based on <em>t</em>-tests to identify the specific measurements/groups differences. If the researchers have specific hypotheses about certain group differences, these comparisons should be planned in advance. For instance, a researcher may predict that intervention A is superior to B and C. In such cases, the a priori power analysis should be based on those planned comparisons, rather than the overall ANOVA result. In contrast, when researchers do not have a specific hypotheses, they may just perform post hoc comparisons to explore potential differences after finding a significant overall effect. These are more exploratory in nature and typically require correction for multiple comparisons.</p>
<p>To perform power analysis for research designs with more than two levels, we will (when possible) rely on two approaches. First, we will use the <code>faux</code> package to simulate factorial data and analyze it with base R’s <code>aov()</code> and <code>emmeans()</code> for planned comparisons. For the second approach, we will be using <code>Superpower</code> to both simulate data and perform the analysis. <code>Superpower</code> relies on <code>emmeans</code> for planned comparisons.</p>
</section>
<section id="one-factor-repeated-measures-design" class="level2" data-number="5.4">
<h2 data-number="5.4"><span class="header-section-number">5.4</span> One-factor repeated-measures design</h2>
<p>In a repeated-measure factorial designs researchers collect data from the same participants at more than two different time points or conditions. Typically researchers will use a one-way within-subject ANOVA to analyse this study design.</p>
<p>Suppose a researcher hypothesizes that intervention A is more effective than interventions B and C in reducing heart rate. To test this hypothesis, the researcher plans to use a within-subjects (repeated measures) design with three levels, collecting heart rate data from the same participants under each intervention condition.</p>
<div class="callout-message">
<p>This hypothesis specifies a directional expectation—that intervention A will lead to lower heart rates compared to interventions B and C—rather than merely predicting that differences exist between conditions. Therefore, the researcher should use planned contrasts or directional (one-tailed) tests that align with the hypothesis, rather than relying solely on the omnibus <em>F</em>-test, which only assesses whether any difference exists among the conditions.</p>
</div>
<p>Let’s define the parameters for the simulation:</p>
<div class="cell">
<div class="sourceCode" id="cb55"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                         <span class="co"># number of simulations</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">75</span>, <span class="dv">100</span>)     <span class="co"># total sample size</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">62</span>, <span class="dv">65</span>)                   <span class="co"># expected group means per for A, B, C</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                              <span class="co"># common SD</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.6</span>                            <span class="co"># correlation between measurements</span></span></code></pre></div>
</div>
<section id="simulation-using-aov" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1"><span class="header-section-number">5.4.1</span> Simulation using <code>aov()</code></h3>
<p>Before running the simulation, always make sure that the pattern of means matches the expected pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb56"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_design</span>(</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">condition =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)),</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> <span class="dv">25</span>,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">TRUE</span>, </span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    ) </span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_37-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Let’s perform the simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb57"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform simulations</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">condition =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)),</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">long =</span> <span class="cn">TRUE</span>,</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span>, </span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>    ) </span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aov</span>(y <span class="sc">~</span> condition <span class="sc">+</span> <span class="fu">Error</span>(id), df) <span class="sc">|&gt;</span> </span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;condition&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pull</span>(p.value)</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Run for all sample sizes</span></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> sample_size,</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant </span></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">25</td>
<td style="text-align: right;">0.67</td>
</tr>
<tr class="even">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.96</td>
</tr>
<tr class="odd">
<td style="text-align: right;">75</td>
<td style="text-align: right;">0.99</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">1.00</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>The above simulation provides power estimates only for the overall <em>F</em>-test, which tests the null hypothesis that the three conditions are equal. However, in our example the researcher had a specific expected pattern of means (A &lt; B and A &lt; C). Since the hypothesis of interest concerns a specific set of pairwise comparisons, the researcher should ensure that both comparisons are adequately powered. Pairwise comparisons can be tested using <code>Superpower.</code></p>
</section>
<section id="simulation-using-superpower" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2"><span class="header-section-number">5.4.2</span> Simulation using <code>Superpower</code></h3>
<p>Let’s define the study design:</p>
<div class="cell">
<div class="sourceCode" id="cb58"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>design_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_design</span>(</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">design =</span> <span class="st">&quot;3w&quot;</span>,  <span class="co"># study design (i.e., three within-subject measurements)</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">50</span>,</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> mu,</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> sd,</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> rho,</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">labelnames =</span> <span class="fu">c</span>(<span class="st">&quot;group&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>),</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot =</span> <span class="cn">TRUE</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_39-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Setting <code>ANOVA_design(plot = TRUE)</code> returns a plot of the condition means, which is useful for verifying that the intended pattern of means has been specified correctly.</p>
<p>Now let’s run the simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb59"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulation</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>simulation_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_power</span>(</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>  design_result, </span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha_level =</span> alpha_level, </span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">nsims =</span> nsims, </span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">FALSE</span>,</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">050990</span>) <span class="co"># for reproducibility</span></span></code></pre></div>
</div>
<p>The power calculation of the omnibus <em>F</em>-test:</p>
<div class="cell">
<div class="sourceCode" id="cb60"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>simulation_result<span class="sc">$</span>main_results <span class="sc">|&gt;</span> </span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">effect_size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">anova_group</td>
<td style="text-align: right;">95.3</td>
<td style="text-align: right;">0.15</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Note that the achieved power is almost identical to the power achieved using <code>aov()</code>.</p>
<p>The power calculation of the pairwise comparisons:</p>
<div class="cell">
<div class="sourceCode" id="cb61"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>simulation_result<span class="sc">$</span>pc_results <span class="sc">|&gt;</span> </span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">effect_size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">p_group_A_group_B</td>
<td style="text-align: right;">35.9</td>
<td style="text-align: right;">0.23</td>
</tr>
<tr class="even">
<td style="text-align: left;">p_group_A_group_C</td>
<td style="text-align: right;">97.7</td>
<td style="text-align: right;">0.57</td>
</tr>
<tr class="odd">
<td style="text-align: left;">p_group_B_group_C</td>
<td style="text-align: right;">64.2</td>
<td style="text-align: right;">0.34</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Although the <em>F</em>-test has adequate power to reject the null hypothesis of no difference across conditions (i.e., power = ), only the pairwise comparison between interventions A and C has adequate power (i.e., power = 97.7. Because the difference in heart rate between A and C is larger than that between A and B, the pairwise comparison test for A vs C achieves higher power for any given sample size. Therefore, a larger sample size would be needed to attain comparable power for the A vs B comparison.</p>
</section>
</section>
<section id="one-factor-between-subject-design" class="level2" data-number="5.5">
<h2 data-number="5.5"><span class="header-section-number">5.5</span> One-factor between-subject design</h2>
<p>In a between-subject factorial design researchers collect data from participants that were assigned to more than two different groups. Typically researchers will analyse this study design with a one-way between-subject subject ANOVA.</p>
<p>Suppose a researcher aims to compare the effectiveness of two doses against a placebo by randomly assigning participants to one of three intervention groups. The intervention will be considered effective if <strong>any</strong> of the two doses result in a significantly reduced heart rate compared to the placebo. Because this involves two multiple comparisons, appropriate adjustments for multiple testing are required in the analysis (i.e., 0.05/2), and these adjustments must be incorporated into the power analysis.</p>
<p>Let’s define the parameters of the simulation:</p>
<div class="cell">
<div class="sourceCode" id="cb62"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters </span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                    <span class="co"># number of simulations</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>)   <span class="co"># sample size per group</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">62</span>, <span class="dv">64</span>)              <span class="co"># expected group means </span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                         <span class="co"># common SD</span></span></code></pre></div>
</div>
<section id="simulation-using-lm-2" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1"><span class="header-section-number">5.5.1</span> Simulation using <code>lm()</code></h3>
<p>Let’s define the study design:</p>
<div class="cell">
<div class="sourceCode" id="cb63"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_design</span>(</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">between =</span> <span class="fu">list</span>(<span class="at">dose =</span> <span class="fu">c</span>(<span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;placebo&quot;</span>)),</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> <span class="dv">50</span>,</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu =</span> mu,</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> sd,</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot =</span> <span class="cn">TRUE</span>,</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_44-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Let’s perform the simulations with this expected pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb64"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for reproducibility purposes</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)              </span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform simulations</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">dose =</span> <span class="fu">c</span>(<span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;placebo&quot;</span>)),</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the between-subject ANOVA with lm()</span></span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> dose, df)</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># P-value from overall model</span></span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>    overall_p <span class="ot">&lt;-</span> <span class="fu">anova</span>(model)<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">1</span>]</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pairwise comparisons using emmeans</span></span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>    emm <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(model, <span class="sc">~</span> dose)</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>    contrasts <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">contrast</span>(emm, <span class="at">method =</span> <span class="st">&quot;pairwise&quot;</span>))</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract p-values for planned comparisons</span></span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(</span>
<span id="cb64-27"><a href="#cb64-27" aria-hidden="true" tabindex="-1"></a>      <span class="at">overall =</span> overall_p,</span>
<span id="cb64-28"><a href="#cb64-28" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;high - placebo&quot;</span> <span class="ot">=</span> contrasts<span class="sc">$</span>p.value[contrasts<span class="sc">$</span>contrast <span class="sc">==</span> <span class="st">&quot;high - placebo&quot;</span>],</span>
<span id="cb64-29"><a href="#cb64-29" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;medium - placebo&quot;</span> <span class="ot">=</span> contrasts<span class="sc">$</span>p.value[contrasts<span class="sc">$</span>contrast <span class="sc">==</span> <span class="st">&quot;medium - placebo&quot;</span>]</span>
<span id="cb64-30"><a href="#cb64-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb64-31"><a href="#cb64-31" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb64-32"><a href="#cb64-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb64-33"><a href="#cb64-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># p_values is 3 x nsims matrix, calculate proportion significant</span></span>
<span id="cb64-34"><a href="#cb64-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(</span>
<span id="cb64-35"><a href="#cb64-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">comparison =</span> <span class="fu">c</span>(<span class="st">&quot;overall F-test&quot;</span>, <span class="st">&quot;high - placebo&quot;</span>, <span class="st">&quot;medium - placebo&quot;</span>),</span>
<span id="cb64-36"><a href="#cb64-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">power =</span> <span class="fu">c</span>(</span>
<span id="cb64-37"><a href="#cb64-37" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mean</span>(p_values[<span class="dv">1</span>, ] <span class="sc">&lt;</span> <span class="fl">0.05</span>),</span>
<span id="cb64-38"><a href="#cb64-38" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mean</span>(p_values[<span class="dv">2</span>, ] <span class="sc">&lt;</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>),</span>
<span id="cb64-39"><a href="#cb64-39" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mean</span>(p_values[<span class="dv">3</span>, ] <span class="sc">&lt;</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb64-40"><a href="#cb64-40" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb64-41"><a href="#cb64-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">N =</span> n</span>
<span id="cb64-42"><a href="#cb64-42" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb64-43"><a href="#cb64-43" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb64-44"><a href="#cb64-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-45"><a href="#cb64-45" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">map_dfr</span>(sample_size, simulate_power)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb65"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">%&gt;%</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(comparison <span class="sc">==</span> <span class="st">&quot;overall F-test&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(N, power) <span class="sc">%&gt;%</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Power for F-test&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Power for F-test</caption>
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.40</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.72</td>
</tr>
<tr class="odd">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.87</td>
</tr>
</tbody>
</table>


</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb66"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">%&gt;%</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(comparison <span class="sc">==</span> <span class="st">&quot;high - placebo&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(N, power) <span class="sc">%&gt;%</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Power for high dose vs. placebo&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Power for high dose vs. placebo</caption>
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.26</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.60</td>
</tr>
<tr class="odd">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.79</td>
</tr>
</tbody>
</table>


</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb67"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Table for A vs C</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">%&gt;%</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(comparison <span class="sc">==</span> <span class="st">&quot;medium - placebo&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(N, power) <span class="sc">%&gt;%</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Power for medium dose vs. placebo&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Power for medium dose vs. placebo</caption>
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.05</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.11</td>
</tr>
<tr class="odd">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.20</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
<section id="simulation-using-superpower-1" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2"><span class="header-section-number">5.5.2</span> Simulation using <code>Superpower</code></h3>
<p>Let’s define the study design:</p>
<div class="cell">
<div class="sourceCode" id="cb68"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>design_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_design</span>(</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">design =</span> <span class="st">&quot;3b&quot;</span>,         <span class="co"># study design (i.e., three between-subject measurements</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">50</span>,                <span class="co"># sample size per group</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> mu,</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> sd,</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">labelnames =</span> <span class="fu">c</span>(<span class="st">&quot;dose&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;placebo&quot;</span>),</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot =</span> <span class="cn">TRUE</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_49-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Now let’s perform the simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb69"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulation</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>simulation_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_power</span>(</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>  design_result, </span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha_level =</span> <span class="fl">0.05</span>, </span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">nsims =</span> nsims, </span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">FALSE</span>,</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">contrast_type =</span> <span class="st">&quot;pairwise&quot;</span>,</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">emm_p_adjust =</span> <span class="fl">0.05</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">050990</span></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<p>The power calculation of the omnibus <em>F</em>-test:</p>
<div class="cell">
<div class="sourceCode" id="cb70"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>simulation_result<span class="sc">$</span>main_results <span class="sc">|&gt;</span> </span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">effect_size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">anova_dose</td>
<td style="text-align: right;">42.3</td>
<td style="text-align: right;">0.04</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Note that the achieved power is almost identical to the power achieved using <code>aov()</code>.</p>
<p>The power calculation of the pairwise comparisons:</p>
<div class="cell">
<div class="sourceCode" id="cb71"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>simulation_result<span class="sc">$</span>pc_results <span class="sc">|&gt;</span> </span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">effect_size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">p_dose_high_dose_medium</td>
<td style="text-align: right;">16.4</td>
<td style="text-align: right;">0.21</td>
</tr>
<tr class="even">
<td style="text-align: left;">p_dose_high_dose_placebo</td>
<td style="text-align: right;">52.3</td>
<td style="text-align: right;">0.41</td>
</tr>
<tr class="odd">
<td style="text-align: left;">p_dose_medium_dose_placebo</td>
<td style="text-align: right;">16.6</td>
<td style="text-align: right;">0.21</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Now suppose a researcher hypothesizes that intervention A is more effective than Intervention B, and intervention B is more effective than intervention C in reducing heart rate. This directional hypothesis can be tested by specifying a set of custom contrasts—that is, testing linear combinations of group means that reflect the predicted order (A &gt; B &gt; C).</p>
<p>To evaluate this hypothesis, the researcher plans to use a between-subjects design, randomly assigning participants to three independent groups, each receiving one of the three interventions. Planned contrasts will then be used to test the specific pattern of differences.</p>
<p>Let’s define the parameters of the simulation and plot the expected pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb72"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                       <span class="co"># number of simulations</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>)     <span class="co"># sample size per group</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">66</span>, <span class="dv">68</span>, <span class="dv">70</span>)                 <span class="co"># expected group means </span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                            <span class="co"># common SD</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Show pattern of means</span></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>  dat <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">between =</span> <span class="fu">list</span>(<span class="at">intervention =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)),</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> n,</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu =</span> mu,</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> sd,</span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot =</span> <span class="cn">TRUE</span></span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_53-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>To reflect the directional hypothesis that intervention A &lt; Intervention B &lt; Intervention C in terms of effectiveness (e.g., reducing heart rate), the contrast weights can be specified as –1, 0, and +1, respectively. This linear contrast tests whether there is a monotonic increase in the outcome across the three groups in the hypothesized order.</p>
<p>Result of power calculation for the linear contrast:</p>
<div class="cell">
<div class="sourceCode" id="cb73"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>) </span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform simulations</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Run nsims simulations</span></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate between-subjects data</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">intervention =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)),</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span>,</span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">long =</span> <span class="cn">TRUE</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit linear model</span></span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> intervention, <span class="at">data =</span> df)</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Estimate marginal means</span></span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>    emms <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(model, <span class="sc">~</span> intervention)</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define linear contrast: A = -1, B = 0, C = +1</span></span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>    contrast_list <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">linear_trend =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform contrast test and return p-value</span></span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>    contrast_res <span class="ot">&lt;-</span> <span class="fu">contrast</span>(emms, contrast_list)</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summary</span>(contrast_res)<span class="sc">$</span>p.value</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Return proportion of significant p-values</span></span>
<span id="cb73-34"><a href="#cb73-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)</span>
<span id="cb73-35"><a href="#cb73-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb73-36"><a href="#cb73-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-37"><a href="#cb73-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Run for all sample sizes</span></span>
<span id="cb73-38"><a href="#cb73-38" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb73-39"><a href="#cb73-39" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> sample_size,</span>
<span id="cb73-40"><a href="#cb73-40" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb73-41"><a href="#cb73-41" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb73-42"><a href="#cb73-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-43"><a href="#cb73-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Print formatted table</span></span>
<span id="cb73-44"><a href="#cb73-44" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb73-45"><a href="#cb73-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Power for Linear Contrast (A &lt; B &lt; C)&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb73-46"><a href="#cb73-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>Power for Linear Contrast (A</caption>
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">N</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.48</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.81</td>
</tr>
<tr class="odd">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.93</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
</section>
<section id="two-factor-repeated-measures-design" class="level2" data-number="5.6">
<h2 data-number="5.6"><span class="header-section-number">5.6</span> Two-factor repeated-measures design</h2>
<p>In a two-way repeated-measures factorial design, researchers collect data from the same participants under all combinations of two within-subject factors. This means each participant is exposed to every level of both factors, allowing researchers to examine main effects and interactions.</p>
<p>Suppose a researcher hypothesizes that intervention A is more effective than intervention B in reducing heart rate, but that the effectiveness of intervention A will be increased in the morning compared to the evening. The researchers is specifically interested in:</p>
<ul>
<li><p>Comparing whether intervention A is superior to be B both in the morning and evening; and</p></li>
<li><p>Comparing whether the effect of the intervention A is superior in the morning vs. evening</p></li>
</ul>
<p>Let’s define the parameters of the simulation and plot the expected pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb74"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>               <span class="co"># number of simulations</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">61</span>, <span class="dv">63</span>, <span class="dv">68</span>, <span class="dv">68</span>)     <span class="co"># means</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">105</span>                    <span class="co"># sample size</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                    <span class="co"># SD</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fl">0.5</span>                    <span class="co"># correlation between measurements</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>string <span class="ot">=</span> <span class="st">&quot;2w*2w&quot;</span>            <span class="co"># study design (i.e., two within-subject factors)</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span> </span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Show plot</span></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>design_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_design</span>( </span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">design =</span> string, </span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> n, </span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> mu, </span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> sd, </span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> r,</span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot =</span> <span class="cn">TRUE</span>,</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">labelnames =</span> <span class="fu">c</span>(<span class="st">&quot;intervention&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;time&quot;</span>, <span class="st">&quot;morning&quot;</span>, <span class="st">&quot;evening&quot;</span>))</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_55-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Let’s perform the simulations with this expected pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb75"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulation</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>simulation_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_power</span>(</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>  design_result, </span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha_level =</span> alpha_level, </span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">nsims =</span> nsims, </span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">FALSE</span>,</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">050990</span>)</span></code></pre></div>
</div>
<p>Result of power calculation for the interaction effect:</p>
<div class="cell">
<div class="sourceCode" id="cb76"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>simulation_result<span class="sc">$</span>main_results <span class="sc">|&gt;</span> </span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">effect_size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">anova_intervention</td>
<td style="text-align: right;">100.0</td>
<td style="text-align: right;">0.4206939</td>
</tr>
<tr class="even">
<td style="text-align: left;">anova_time</td>
<td style="text-align: right;">28.7</td>
<td style="text-align: right;">0.0279819</td>
</tr>
<tr class="odd">
<td style="text-align: left;">anova_intervention:time</td>
<td style="text-align: right;">28.3</td>
<td style="text-align: right;">0.0277210</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>The current design provides adequate statistical power <strong>(</strong>&gt; 80%) to detect the main effect of the intervention.</p>
<p>Result of power calculation for the planned pairwise comparisons:</p>
<div class="cell">
<div class="sourceCode" id="cb77"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a> pwc <span class="ot">&lt;-</span> simulation_result<span class="sc">$</span>pc_results[<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span> , <span class="dv">5</span>),<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a> pwc <span class="sc">|&gt;</span> </span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">effect_size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">p_intervention_A_time_morning_intervention_A_time_evening</td>
<td style="text-align: right;">51.9</td>
<td style="text-align: right;">0.1974114</td>
</tr>
<tr class="even">
<td style="text-align: left;">p_intervention_A_time_morning_intervention_B_time_morning</td>
<td style="text-align: right;">100.0</td>
<td style="text-align: right;">0.7022056</td>
</tr>
<tr class="odd">
<td style="text-align: left;">p_intervention_A_time_evening_intervention_B_time_evening</td>
<td style="text-align: right;">100.0</td>
<td style="text-align: right;">0.5023257</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>The study design would achieve a power of 0.1974114 to test the comparison of intervention A between morning and evening, a power of 0.7022056 to test for the comparison between interventions A and B in the morning and a power of 0.5023257 to test for the comparison between interventions A and B in the evening. To ensure adequate power (80%) for the second pairwise comparison, the researcher should consider increasing the sample size.</p>
</section>
<section id="two-factor-mixed-design" class="level2" data-number="5.7">
<h2 data-number="5.7"><span class="header-section-number">5.7</span> Two-factor mixed design</h2>
<p>In a two-factor mixed design (i.e., one between- and one-within-subject design), researchers collect data from participants who were assigned to independent groups (a between-subject factor) and also measured on multiple occasions or conditions (a within-subject factor). This design combines both within- and between-subject factors. When the within-subject factor involves measurements before and after an intervention, the design is specifically referred to as a split-plot design.</p>
<p>In interventions following a split-plot design, it is crucial to account for baseline differences between groups. The most effective way to do this is by including baseline covariates, such as pre-intervention scores, in the analysis model. This approach adjusts the post-intervention outcome for initial differences, thereby yielding a more accurate estimate of the intervention effect and increasing power. While several models have been proposed for analyzing split-plot designs—such as comparing difference scores between groups or testing interaction effects—there is broad consensus that including the the pre-intervention scores as a covariate is the most appropriate method. Including baseline scores as a covariate improves the precision of group comparisons by reducing the error variance associated with the covariate and thus increasing power.</p>
<p>Suppose a researcher hypothesizes that intervention A is more effective than intervention B in reducing heart rate. To test this hypothesis, participants are assigned to either intervention A or intervention B (between-subjects factor: intervention type). Heart rate is measured both before and after the intervention (within-subjects factor: time), allowing the researcher to assess intervention effects over time. The primary test of interest is the interaction effect between intervention type and time, which indicates whether the change in heart rate differs between the two interventions.</p>
<p>Let’s define the parameters:</p>
<div class="cell">
<div class="sourceCode" id="cb78"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                            <span class="co"># number of simulations</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>)       <span class="co"># sample size per group</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">64</span>, <span class="dv">60</span>, <span class="dv">64</span>, <span class="dv">64</span>)                  <span class="co"># means for A_pre, A_post, B_pre, B_post</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                                 <span class="co"># common SD</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.7</span>                               <span class="co"># correlation between measurements</span></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span>                      <span class="co"># alpha level</span></span></code></pre></div>
</div>
<p>Let’s visualize the pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb79"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_design</span>(</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;pre&quot;</span>, <span class="st">&quot;post&quot;</span>)),</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">intervention =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>)),</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> <span class="dv">50</span>,</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_60-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<section id="simulation-using-lm-including-time-as-a-covariate" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1"><span class="header-section-number">5.7.1</span> Simulation using <code>lm()</code> including time as a covariate</h3>
<div class="cell">
<div class="sourceCode" id="cb80"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>) </span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Power simulation function</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">within =</span> <span class="fu">list</span>(<span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;pre&quot;</span>, <span class="st">&quot;post&quot;</span>)),</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">intervention =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>)),</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> mu,</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd,</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">r =</span> rho,</span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span>) <span class="sc">|&gt;</span> </span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">intervention =</span> <span class="fu">factor</span>(intervention, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>)))</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>   <span class="fu">lm</span>(post <span class="sc">~</span> intervention <span class="sc">+</span> pre, <span class="at">data =</span> df) <span class="sc">|&gt;</span> </span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;interventionA&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pull</span>(p.value)</span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)</span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Run function for all sample sizes</span></span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb80-28"><a href="#cb80-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> sample_size,</span>
<span id="cb80-29"><a href="#cb80-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb80-30"><a href="#cb80-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-31"><a href="#cb80-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-32"><a href="#cb80-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb80-33"><a href="#cb80-33" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb80-34"><a href="#cb80-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb80-35"><a href="#cb80-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">n</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">25</td>
<td style="text-align: right;">0.51</td>
</tr>
<tr class="even">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.80</td>
</tr>
<tr class="odd">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.98</td>
</tr>
<tr class="even">
<td style="text-align: right;">150</td>
<td style="text-align: right;">1.00</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
</section>
<section id="one-factor-between-subject-design-with-a-continuous-predictor" class="level2" data-number="5.8">
<h2 data-number="5.8"><span class="header-section-number">5.8</span> One-factor between-subject design with a continuous predictor</h2>
<p>This design is similar to the one-way ANOVA but it incorporate a covariate, what is known as an analysis of covariance (ANCOVA). It is used to compare the means of an outcome across two or more groups while controlling for the influence of other variables, called covariates. In other words, ANCOVA allows researchers to compare adjusted group means, accounting for the variability associated with the covariate. Including a covariate improves the precision of group comparisons by reducing the error variance associated with the covariate and thus increasing power.</p>
<p>Suppose a researcher hypothesizes that heart rate differs between individuals who did and did not consume alcohol the previous night. To control for the potential influence of physical fitness, the researcher includes “physical fitness” as a covariate. In this case: 1) heart rate is the primary outcome, 2) alcohol intake (yes or no) is the independent grouping variable, and 3) physical fitness (hours of physical activity per week) is the covariate. By including physical fitness as a covariate, the researcher can control for its influence and better isolate the effect of alcohol consumption on heart rate.</p>
<p>Let’s define the parameters of the simulation and plot the pattern of means:</p>
<div class="cell">
<div class="sourceCode" id="cb81"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                              <span class="co"># number of simulations</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>)   <span class="co"># sample size</span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">64</span>                                  <span class="co"># mean heart rate for alcohol group</span></span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="dv">60</span>                                  <span class="co"># mean heart rate for non-alcohol group</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                                   <span class="co"># SD for both groups</span></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>mu3 <span class="ot">&lt;-</span> <span class="dv">5</span>                                   <span class="co"># means hours of exercise (covariate)</span></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>sd3 <span class="ot">&lt;-</span> <span class="dv">3</span>                                   <span class="co"># SD of the covariate</span></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.8</span>                                 <span class="co"># correlation between heart rate and exercise</span></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">&quot;alcohol&quot;</span>, <span class="st">&quot;noalcohol&quot;</span>)), </span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">list</span>(<span class="at">alcohol =</span> mu1, <span class="at">noalcohol =</span> mu2), </span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd, </span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb81-17"><a href="#cb81-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">TRUE</span></span>
<span id="cb81-18"><a href="#cb81-18" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb81-19"><a href="#cb81-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">exercise =</span> <span class="fu">rnorm_pre</span>(y, mu3, sd3, rho))</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_62-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Let’s run the simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb82"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>) </span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Power simulation function</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>  p_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">between =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">&quot;alcohol&quot;</span>, <span class="st">&quot;noalcohol&quot;</span>)), </span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">mu =</span> <span class="fu">list</span>(<span class="at">alcohol =</span> mu1, <span class="at">noalcohol =</span> mu2), </span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> sd, </span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">plot =</span> <span class="cn">FALSE</span></span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">exercise =</span> <span class="fu">rnorm_pre</span>(y, mu3, sd3, rho))</span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure group is treated as a factor</span></span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>    df<span class="sc">$</span>group <span class="ot">&lt;-</span> <span class="fu">factor</span>(df<span class="sc">$</span>group, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;noalcohol&quot;</span>, <span class="st">&quot;alcohol&quot;</span>))</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lm</span>(y <span class="sc">~</span> group <span class="sc">+</span> exercise, <span class="at">data =</span> df) <span class="sc">|&gt;</span> </span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>      broom<span class="sc">::</span><span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;groupalcohol&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pull</span>(p.value)</span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb82-24"><a href="#cb82-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(p_values <span class="sc">&lt;</span> alpha_level)</span>
<span id="cb82-25"><a href="#cb82-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb82-26"><a href="#cb82-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-27"><a href="#cb82-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Run function for all sample sizes</span></span>
<span id="cb82-28"><a href="#cb82-28" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb82-29"><a href="#cb82-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> sample_size,</span>
<span id="cb82-30"><a href="#cb82-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb82-31"><a href="#cb82-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb82-32"><a href="#cb82-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-33"><a href="#cb82-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Return proportion of significant p-values</span></span>
<span id="cb82-34"><a href="#cb82-34" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb82-35"><a href="#cb82-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb82-36"><a href="#cb82-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">n</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.23</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.41</td>
</tr>
<tr class="odd">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.53</td>
</tr>
<tr class="even">
<td style="text-align: right;">200</td>
<td style="text-align: right;">0.68</td>
</tr>
<tr class="odd">
<td style="text-align: right;">250</td>
<td style="text-align: right;">0.76</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
<section id="equivalence-tests" class="level2" data-number="5.9">
<h2 data-number="5.9"><span class="header-section-number">5.9</span> Equivalence tests</h2>
<p>So far, our goal has been to establish that groups or conditions were statistically significantly different. However, researchers might also be interested in demonstrating that two groups or conditions do not differ by a meaningful amount-that is, any difference is negligible or practically equivalent to zero. To assess this, researchers can use equivalence tests, which are designed to establish whether the observed difference fall within a predefined range of practical equivalence.</p>
<p>Importantly, to establish equivalence, researchers must first define the equivalence bounds based on the smallest effect size of interest (SESOI). The SESOI represents the smallest effect size considered meaningful for practical or theoretical reasons, and it should be specified in advance—ideally as part of the preregistration document. Briefly, an equivalence test consists of two one-sided tests, where the goal is to reject the presence of effects outside of the equivalence bounds. If both one-sided tests yield a significant <em>p</em>-value, researchers can claim that both groups or conditions are equivalent. Alternatively, if the 90% CI of the observed effect falls entirely within the equivalence bounds, equivalence can also be claimed.</p>
<p>For a detailed discussion on equivalence testing, readers are referred to <span class="citation" data-cites="lakens_equivalence_2017">Daniël Lakens (<a href="#ref-lakens_equivalence_2017" role="doc-biblioref">2017</a>)</span> and <span class="citation" data-cites="lakens_equivalence_2018">Daniël Lakens, Scheel, and Isager (<a href="#ref-lakens_equivalence_2018" role="doc-biblioref">2018</a>)</span>. For a discussion on SESOI, readers are referred to <span class="citation" data-cites="lakens_sample_justification">Daniël Lakens (<a href="#ref-lakens_sample_justification" role="doc-biblioref">2022b</a>)</span>. For a practical, simulation-based approach to equivalence testing, readers are referred to <span class="citation" data-cites="riesthuis_simulations">Riesthuis (<a href="#ref-riesthuis_simulations" role="doc-biblioref">2024</a>)</span>.</p>
<p>Suppose a researcher hypothesizes that the difference in heart rate between intervention A and B will not exceed 5 bpm, corresponding to a Cohen’s <em>d<sub>s</sub></em> of 0.2 (5/25 = 0.2). In this line of research, the SESOI has been set to ± 10, corresponding to a Cohen’s <em>d<sub>s</sub></em> of 0.2 (10/25 = 0.4). This means that any observed difference between the two interventions smaller than 0.3 (in either direction) is considered practically equivalent—that is, not large enough to be meaningful in practice. As illustrated below, if the 90% CI entirely within the lower and upper bounds of the SESOI.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure9" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure9-1.png" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 9: The grey vertical lines represent the lower and upper bound of the SESOI corresponding to the region of equivalence. The horizontal black line represents the 90% CI of the observed effect.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Let’s conduct an a priori power analysis for an equivalence test with the following parameters:</p>
<div class="cell">
<div class="sourceCode" id="cb83"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>res_t_TOST <span class="ot">&lt;-</span> <span class="fu">power_t_TOST</span>(<span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">delta =</span> <span class="dv">5</span>,           <span class="co"># true difference in means</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">sd =</span> <span class="dv">25</span>,             <span class="co"># standard deviation of the difference</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">power =</span> <span class="fl">0.8</span>,</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">eqb =</span> <span class="dv">10</span>,            <span class="co"># set upper and lower bounds</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>                           <span class="at">type =</span> <span class="st">&quot;unpaired&quot;</span>)</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>res_t_TOST</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
      TOST power calculation 

          power = 0.8
           beta = 0.2
          alpha = 0.05
              n = 155.9257
          delta = 5
             sd = 25
         bounds = -10, 10</code></pre>
</div>
</div>
<p>Approximately 156 participants per group would be required to reject the existence of effect sizes larger than ±0.2.</p>
<p>You can also use <code>emmeans</code> within <code>Superpower</code> to perform power analysis for equivalence tests in pairwise comparisons. This approach can be useful when researchers plan to use a factorial design and want to test both:</p>
<ul>
<li><p>A hypothesis of no difference (equivalence) between interventions or conditions, and</p></li>
<li><p>A hypothesis of difference between other interventions or conditions</p></li>
</ul>
<p>For example, suppose a researcher expects that the time of day of exposure to Intervention A does not affect its efficacy in reducing heart rate (i.e., morning vs evening are equivalent), but also expects that Intervention A and B differ their effects both in the morning and in the evening.</p>
<div class="cell">
<div class="sourceCode" id="cb85"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>design_result <span class="ot">&lt;-</span> <span class="fu">ANOVA_design</span>(</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">design =</span> <span class="st">&quot;2b*2b&quot;</span>,  <span class="co"># study design (i.e., two-factor between-subject design)</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="dv">50</span>,</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">60</span>, <span class="dv">62</span>, <span class="dv">67</span>, <span class="dv">67</span>),</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> <span class="dv">10</span>,</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">labelnames =</span> <span class="fu">c</span>(<span class="st">&quot;intervention&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, </span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&quot;time&quot;</span>, <span class="st">&quot;morning&quot;</span>, <span class="st">&quot;evening&quot;</span>),</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot =</span> <span class="cn">TRUE</span></span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure>
<p><img src="hands-on_guidelines_files/figure-html/chunk_66-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Let’s simulate a single dataset:</p>
<div class="cell">
<div class="sourceCode" id="cb86"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">ANOVA_exact</span>(</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>  design_result,</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha_level =</span> <span class="fl">0.05</span>,</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">FALSE</span>,</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">emm =</span> <span class="cn">TRUE</span>,</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">contrast_type =</span> <span class="st">&quot;pairwise&quot;</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</div>
<p>Unlike <code>ANOVA_power()</code>, which performs multiple simulations to estimate power, <code>ANOVA_exact()</code> generates a single dataset that exactly matches the properties specified in <code>ANOVA_design()</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb87"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>result<span class="sc">$</span>emm_results[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">6</span>),] <span class="sc">|&gt;</span> </span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: left;" data-quarto-table-cell-role="th">contrast</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">partial_eta_squared</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">cohen_f</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">non_centrality</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">intervention_A time_evening - intervention_B time_evening</td>
<td style="text-align: right;">70.1</td>
<td style="text-align: right;">0.0</td>
<td style="text-align: right;">0.2</td>
<td style="text-align: right;">6.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">intervention_A time_morning - intervention_B time_morning</td>
<td style="text-align: right;">93.6</td>
<td style="text-align: right;">0.1</td>
<td style="text-align: right;">0.2</td>
<td style="text-align: right;">12.2</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>This study design would have adequate power (&gt;80%) to reject both null hypothesis of no difference between intervention A and B when compared at the same time of exposure.</p>
<p>Now let’s conduct the power analysis for the hypothesis of equivalence, specifically testing whether the efficacy of Intervention A is equivalent across different times of exposure.</p>
<div class="cell">
<div class="sourceCode" id="cb88"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>simple_condition_effects <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>  result<span class="sc">$</span>emmeans<span class="sc">$</span>emmeans,</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">specs =</span> <span class="sc">~</span> time<span class="sc">|</span>intervention</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>equivalence_power <span class="ot">&lt;-</span> <span class="fu">emmeans_power</span>(</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pairs</span>(simple_condition_effects, </span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">side =</span> <span class="st">&quot;equivalence&quot;</span>, </span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">delta =</span> <span class="dv">5</span>)[<span class="dv">1</span>] <span class="co"># select comparison of interest (Intervention A: morning vs. evening)</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>equivalence_power <span class="sc">|&gt;</span> </span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">contrast</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">intervention</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">partial_eta_squared</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">cohen_f</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">non_centrality</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">time_evening - time_morning</td>
<td style="text-align: left;">intervention_A</td>
<td style="text-align: right;">32</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.1</td>
<td style="text-align: right;">2.3</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>With this study design, the equivalence test would have a power of <code>r``round(equivalence_power[3], 1)</code> to establish equivalence, assuming 2 bpm difference in heart rate for Intervention A between morning and evening.</p>
<p>Because power is calculated from the squared <em>t</em>-value, power is only calculated correctly if the alternative hypothesis is true in the simulated dataset. That is, the difference between the condition means is consistent with the tested directional hypothesis (smaller than <code>delta</code>).</p>
<div class="callout-message">
<p>The required sample size per group increases as the difference between the expected effect size and the SESOI decreases. This is because it becomes harder to statistically rule out effects that approach the boundaries of practical relevance. For example, if a researcher expects the true difference to be <em>d</em> = 0.2, but the SESOI is set at ±0.3, the test must reliably detect that the effect is <em>not as large as</em> ±0.3 — requiring a sufficiently precise estimate (i.e., a narrower confidence interval that exclude 0.3), which in turn requires a larger sample. This mirrors the logic of NHST: a study requires a larger sample size to detect <em>d</em> = 0.2 than to detect <em>d</em> = 0.4.</p>
</div>
</section>
<section id="minimum-effect-tests" class="level2" data-number="5.10">
<h2 data-number="5.10"><span class="header-section-number">5.10</span> Minimum-effect tests</h2>
<p>When using an equivalence test, the goal is to reject effect sizes larger than the SESOI to demonstrate equivalence between two interventions. In contrast, there are situations where researchers aim to do the opposite: to reject the presence of negligible effects and show that an observed effect is meaningfully large. This is the purpose of a minimum-effect test—to test whether the observed difference exceeds a predefined SESOI or the smallest effect size considered meaningful. In essence, an effect is considered meaningfully large when the entire confidence interval of the observed effect lies beyond the SESOI bounds—either above the upper bound or below the lower bound, depending on the hypothesis.</p>
<p>Readers are referred to <span class="citation" data-cites="murphy_minimum-effect-test_1999">Murphy and Myors (<a href="#ref-murphy_minimum-effect-test_1999" role="doc-biblioref">1999</a>)</span> for an introduction to minimum-effect tests and to and <span class="citation" data-cites="riesthuis_simulations">Riesthuis (<a href="#ref-riesthuis_simulations" role="doc-biblioref">2024</a>)</span> for a hands-on guide to using simulation-based approaches for implementing minimum-effect tests</p>
<p>Suppose a researcher hypothesizes that the difference between Intervention A and Intervention B will exceed a standardized mean difference of 0.4. In this line of research, the SESOI is set to ±0.2, meaning that any observed difference greater than 0.2 (in either direction) is considered practically meaningful. Therefore, the researcher uses a minimum-effect test to evaluate whether the observed effect exceeds this SESOI threshold, providing evidence that the effect is not only statistically significant but also of meaningful size.</p>
<p>Let’s define the parameters:</p>
<div class="cell">
<div class="sourceCode" id="cb89"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>nsims <span class="ot">&lt;-</span> <span class="dv">1000</span>                                     <span class="co"># number of simulations</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>, <span class="dv">300</span>)     <span class="co"># sample size per group</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">4</span>                                          <span class="co"># expected intervention A mean</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="dv">0</span>                                          <span class="co"># expected intervention B mean</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">10</span>                                          <span class="co"># common SD </span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>lower_bound <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.2</span>                               <span class="co"># lower bound of SESOI</span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>upper_bound <span class="ot">&lt;-</span> <span class="fl">0.2</span>                                <span class="co"># upper bound of SESOI</span></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>alpha_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span></code></pre></div>
</div>
<p>Let’s perform the simulations:</p>
<div class="cell">
<div class="sourceCode" id="cb90"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Power simulation function</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>  es_values <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nsims, {</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate raw data</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>    group_A <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu1, <span class="at">sd =</span> sd)</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>    group_B <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu2, <span class="at">sd =</span> sd)</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run minimum-effect test</span></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>    result <span class="ot">&lt;-</span> <span class="fu">tsum_TOST</span>(</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">m1 =</span> <span class="fu">mean</span>(group_A),</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">m2 =</span> <span class="fu">mean</span>(group_B),</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd1 =</span> <span class="fu">sd</span>(group_A),</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd2 =</span> <span class="fu">sd</span>(group_B),</span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">n1 =</span> n,</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">n2 =</span> n,</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">low_eqbound =</span> lower_bound,</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">high_eqbound =</span> upper_bound,</span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a>      <span class="at">alpha =</span> alpha_level,</span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis =</span> <span class="st">&quot;MET&quot;</span>                           <span class="co"># MET = minimum-effect test</span></span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-25"><a href="#cb90-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if CI excludes the upper or lower bound of the SESOI</span></span>
<span id="cb90-26"><a href="#cb90-26" aria-hidden="true" tabindex="-1"></a>    result<span class="sc">$</span>effsize<span class="sc">$</span>lower.ci[<span class="dv">2</span>] <span class="sc">&gt;</span> upper_bound <span class="sc">|</span> result<span class="sc">$</span>effsize<span class="sc">$</span>upper.ci[<span class="dv">2</span>] <span class="sc">&lt;</span> lower_bound</span>
<span id="cb90-27"><a href="#cb90-27" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb90-28"><a href="#cb90-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb90-29"><a href="#cb90-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(es_values) </span>
<span id="cb90-30"><a href="#cb90-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb90-31"><a href="#cb90-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-32"><a href="#cb90-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Run function for all sample sizes</span></span>
<span id="cb90-33"><a href="#cb90-33" aria-hidden="true" tabindex="-1"></a>power_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb90-34"><a href="#cb90-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_per_group =</span> sample_size,</span>
<span id="cb90-35"><a href="#cb90-35" aria-hidden="true" tabindex="-1"></a>  <span class="at">power =</span> <span class="fu">map_dbl</span>(sample_size, simulate_power)</span>
<span id="cb90-36"><a href="#cb90-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb90-37"><a href="#cb90-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-38"><a href="#cb90-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Return results</span></span>
<span id="cb90-39"><a href="#cb90-39" aria-hidden="true" tabindex="-1"></a>power_results <span class="sc">|&gt;</span> </span>
<span id="cb90-40"><a href="#cb90-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb90-41"><a href="#cb90-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">n_per_group</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.229</td>
</tr>
<tr class="even">
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.385</td>
</tr>
<tr class="odd">
<td style="text-align: right;">150</td>
<td style="text-align: right;">0.535</td>
</tr>
<tr class="even">
<td style="text-align: right;">200</td>
<td style="text-align: right;">0.641</td>
</tr>
<tr class="odd">
<td style="text-align: right;">250</td>
<td style="text-align: right;">0.676</td>
</tr>
<tr class="even">
<td style="text-align: right;">300</td>
<td style="text-align: right;">0.815</td>
</tr>
</tbody>
</table>


</div>
</div>
</section>
<section id="general-linear-mixed-models" class="level2" data-number="5.11">
<h2 data-number="5.11"><span class="header-section-number">5.11</span> (General) Linear Mixed Models</h2>
<p>Linear mixed models are used when data is nested, meaning there are multiple observations for each participant under one or more conditions. For example, in a study investigating the effect of sleep deprivation, two groups of participants (sleep-deprived vs. control) could be measured repeatedly on reaction time across a week. Because measurements are repeated within participants, observations are not independent. Linear mixed models handles the correlation among repeated measurements and provides more accurate estimates than traditional methods like <em>t</em>-tests or repeated measures ANOVA <span class="citation" data-cites="brysbaert_LMEM">(<a href="#ref-brysbaert_LMEM" role="doc-biblioref">Brysbaert and Stevens 2018</a>)</span>. For a gentle introduction to general linear mixed models, readers are referred to <span class="citation" data-cites="brysbaert_LMEM">Brysbaert and Stevens (<a href="#ref-brysbaert_LMEM" role="doc-biblioref">2018</a>)</span>, <span class="citation" data-cites="brysbaert_how_to_LMEM">Brysbaert and Debeer (<a href="#ref-brysbaert_how_to_LMEM" role="doc-biblioref">2025</a>)</span> and <span class="citation" data-cites="brown_introduction_LMEM">Brown (<a href="#ref-brown_introduction_LMEM" role="doc-biblioref">2021</a>)</span>.</p>
<section id="summary-statistics-based-approach" class="level3" data-number="5.11.1">
<h3 data-number="5.11.1"><span class="header-section-number">5.11.1</span> Summary-statistics-based approach</h3>
<p><span class="citation" data-cites="murayama_2022">Murayama, Usami, and Sakaki (<a href="#ref-murayama_2022" role="doc-biblioref">2022</a>)</span> created an app to run power analyses of mixed-effects models with two-level nested data available at <a href="https://koumurayama.shinyapps.io/summary_statistics_based_power/" class="uri">https://koumurayama.shinyapps.io/summary_statistics_based_power/</a>. Their approach relies on the fact that mixed-effects models produce approximately identical results to a simpler statistical test (e.g., one-sample <em>t</em>-test) on aggregated data under certain assumptions (i.e. cluster size and the variance of <em>x</em> are constant across clusters. TTo illustrate this, suppose that a researcher collects 10 data points (Level 1; L1) nested within 50 participants (Level 2; L2). For each participant, 5 data points are from a control condition (sleep deprived) and 5 data points are from an experimental (sleep deprived + caffeine) condition (see <a href="#fig-figure10" class="quarto-xref">Figure 10</a>).</p>
<div class="cell">
<div class="sourceCode" id="cb91"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">050990</span>)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set parameters</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="fl">10.2</span>, <span class="fl">10.3</span>, <span class="fl">10.5</span>, <span class="fl">10.5</span>,</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>        <span class="fl">10.9</span>, <span class="dv">11</span>, <span class="fl">11.5</span>, <span class="fl">11.2</span>, <span class="fl">11.6</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data</span></span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>design <span class="ot">&lt;-</span> <span class="fu">sim_design</span>(</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">within =</span> <span class="fu">list</span>(</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">time =</span> <span class="fu">c</span>(<span class="st">&quot;post1&quot;</span>, <span class="st">&quot;post2&quot;</span>, <span class="st">&quot;post3&quot;</span>, <span class="st">&quot;post4&quot;</span>, <span class="st">&quot;post5&quot;</span>),</span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">condition =</span> <span class="fu">c</span>(<span class="st">&quot;deprived&quot;</span>, <span class="st">&quot;control&quot;</span>)</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> n,</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="fl">10.2</span>, <span class="fl">10.3</span>, <span class="fl">10.5</span>, <span class="fl">10.5</span>,</span>
<span id="cb91-19"><a href="#cb91-19" aria-hidden="true" tabindex="-1"></a>         <span class="fl">10.9</span>, <span class="dv">11</span>, <span class="fl">11.5</span>, <span class="fl">11.2</span>, <span class="fl">11.6</span>),</span>
<span id="cb91-20"><a href="#cb91-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> <span class="dv">3</span>,</span>
<span id="cb91-21"><a href="#cb91-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">r =</span> <span class="fl">0.8</span>,</span>
<span id="cb91-22"><a href="#cb91-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot =</span> <span class="cn">TRUE</span>,</span>
<span id="cb91-23"><a href="#cb91-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">long =</span> <span class="cn">TRUE</span></span>
<span id="cb91-24"><a href="#cb91-24" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure10" class="quarto-float quarto-figure quarto-figure-center" width="672">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="hands-on_guidelines_files/figure-html/fig-figure10-1.png" id="fig-figure10" class="img-fluid" width="672" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-figure10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 10
</figcaption>
</figure>
</div>
</div>
</div>
<p>The first step is to calculate the average of the measurements for each experimental condition:</p>
<div class="cell">
<div class="sourceCode" id="cb92"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> design <span class="sc">|&gt;</span> </span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(id, condition) <span class="sc">|&gt;</span> </span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">average =</span> <span class="fu">mean</span>(y), <span class="at">.groups =</span> <span class="st">&quot;drop&quot;</span>) </span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>df_wide <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span> </span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_from =</span> condition, </span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_from =</span> average</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div>
</div>
<p>The second step is to calculate the the t-statistic using <code>t.test(paired = TRUE)</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb93"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>paired_result <span class="ot">&lt;-</span> <span class="fu">t.test</span>(</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>  df_wide<span class="sc">$</span>deprived, </span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>  df_wide<span class="sc">$</span>control, </span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">paired =</span> <span class="cn">TRUE</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">|&gt;</span> </span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>paired_result <span class="sc">|&gt;</span> </span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">parameter</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">conf.low</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">conf.high</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">method</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-0.33</td>
<td style="text-align: right;">-3.07</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">49</td>
<td style="text-align: right;">-0.54</td>
<td style="text-align: right;">-0.11</td>
<td style="text-align: left;">Paired t-test</td>
<td style="text-align: left;">two.sided</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>This is statistically equivalent to run a mixed model with one fixed effect and with one random effect using <code>lmer()</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb94"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change order of factors to obtain the same estimate (i.e., -0.5 rather than 0.5)</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>condition <span class="ot">&lt;-</span> <span class="fu">factor</span>(df<span class="sc">$</span>condition, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;deprived&quot;</span>))</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lmer</span>(average <span class="sc">~</span> condition <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>id), df) <span class="sc">|&gt;</span> </span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>fit<span class="sc">$</span>coefficients <span class="sc">|&gt;</span> </span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">digits =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span> </span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table caption-top" data-quarto-postprocess="true" style="margin-left: auto; margin-right: auto;">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Std. Error</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">t value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">10.92</td>
<td style="text-align: right;">0.35</td>
<td style="text-align: right;">30.83</td>
</tr>
<tr class="even">
<td style="text-align: left;">conditiondeprived</td>
<td style="text-align: right;">-0.33</td>
<td style="text-align: right;">0.11</td>
<td style="text-align: right;">-3.07</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>Note that both <code>t.test()</code> and <code>lmer()</code> approaches return the same coefficient and the same <em>t</em>-statistic indicating that these two analytic approaches are equivalent. In fact, when the two aforementioned conditions are met (i.e. cluster size and the variance of <em>x</em> are constant across clusters), mixed-effects modelling and summary-statistics (i.e., <em>t</em>-test) approach are mathematically equivalent.</p>
<p>Once we obtain the <em>t</em>-value, we need to convert the <em>t-</em>value to Cohen’s <em>d</em> as if the <em>t-</em>value were obtained from a one-sample <em>t-</em>test with the sample size. This Cohen’s <em>d</em> can be then used to conduct a power analysis of one-sample <em>t</em> test with <em>G*Power</em>, <em>pwr</em>, or other software.</p>
<div class="cell">
<div class="sourceCode" id="cb95"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Cohen&#39;s dz</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> paired_result[[<span class="dv">1</span>,<span class="dv">2</span>]]<span class="sc">/</span><span class="fu">sqrt</span>(n) </span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct power analysis</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>pwr <span class="ot">&lt;-</span> <span class="fu">pwr.t.test</span>(<span class="at">d =</span> d, <span class="at">power =</span> <span class="fl">0.8</span>, <span class="at">sig.level =</span> <span class="fl">0.05</span>, <span class="at">type =</span> <span class="st">&quot;one.sample&quot;</span>)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>pwr</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
     One-sample t test power calculation 

              n = 43.71014
              d = 0.4335832
      sig.level = 0.05
          power = 0.8
    alternative = two.sided</code></pre>
</div>
</div>
<p>Assuming a true effect size of -0.43, our study design would achieve a power of 80% with a sample size of 44.</p>
<p>Alternatively, readers can use the app (<a href="https://koumurayama.shinyapps.io/summary_statistics_based_power/" class="uri">https://koumurayama.shinyapps.io/summary_statistics_based_power/</a>) to reproduce the above power analysis (see <a href="#fig-figure11" class="quarto-xref">Figure 11</a>).</p>
<div class="cell">
<div class="sourceCode" id="cb97"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">include_graphics</span>(<span class="st">&quot;figures/summary-statistics.png&quot;</span>)</span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure11" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/summary-statistics.png" class="img-fluid" width="1403" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 11: A priori power analysis to estimate sample size for L2 based on on the summary-statistic approach
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>The app only provides power estimates of mixed-effects models with two-level nested data (not the models with three-level data or crossed-random effects).</p></li>
<li><p>This app mainly allows researchers to perform power analysis to determine L2 sample size. The app can still show the impact of cluster size on power, but you need to supply more information beyond the the summary statistic and sample size.</p></li>
<li><p>Computed power is based on the assumption that the new study has the same set of predictors as assumed in the calculation.</p></li>
<li><p>When planning only a L2 sample size for a new study, the estimated appropriate L2 sample size is deemed valid only if cluster size (i.e., the number of individual units within each cluster) remains the same as assumed in the calculation.</p></li>
</ul>
</div>
</div>
</section>
<section id="traditional-approach-work-in-progress" class="level3" data-number="5.11.2">
<h3 data-number="5.11.2"><span class="header-section-number">5.11.2</span> Traditional approach (work in progress)</h3>
<p><span class="citation" data-cites="westfall_2014">Westfall, Kenny, and Judd (<a href="#ref-westfall_2014" role="doc-biblioref">2014</a>)</span> created an app to run power analyses for simple designs with one fixed effect and two random factors. The app is available at <a href="#0">https://jakewestfall.shinyapps.io/crossedpower</a>.</p>
</section>
<section id="simulation-based-power-analysis-work-in-progress" class="level3" data-number="5.11.3">
<h3 data-number="5.11.3"><span class="header-section-number">5.11.3</span> Simulation-based power analysis (work in progress)</h3>
<p>An alternative is to use simulation-based power analysis. For a comprehensive tutorial on this approach, readers are referred to <span class="citation" data-cites="debruine_mixed_effects">L. M. DeBruine and Barr (<a href="#ref-debruine_mixed_effects" role="doc-biblioref">2021</a>)</span>.</p>
</section>
</section>
</section>
<section id="transparency-and-computational-reproducibility" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Transparency and computational reproducibility</h1>
<p>A priori power analyses are often not reproducible because researchers frequently fail to provide all the necessary information <span class="citation" data-cites="thibault_errors_power bakker_quality_poweranalysis">(<a href="#ref-thibault_errors_power" role="doc-biblioref">Thibault et al. 2024</a>; <a href="#ref-bakker_quality_poweranalysis" role="doc-biblioref">Bakker et al. 2020</a>)</span>. This lack of transparency not only prevents peers’ from reproducing the analyses, but also limits their ability to evaluate the analytic decisions made by researchers or assess whether the a priori power analysis was performed correctly <span class="citation" data-cites="thibault_errors_power bakker_quality_poweranalysis">(<a href="#ref-thibault_errors_power" role="doc-biblioref">Thibault et al. 2024</a>; <a href="#ref-bakker_quality_poweranalysis" role="doc-biblioref">Bakker et al. 2020</a>)</span>. Therefore, researchers must report all information required to reproduce the a priori power analysis including the test, alpha level, the type and magnitude of the effect size, and how it was derived if researchers had to compute it themselves. In such case, researchers should provide the corresponding formula and reference.</p>
<p>Transparency and reproducibility can be facilitated by sharing the analysis script. When the results of the power analysis cannot be exported or researchers cannot provide the analysis script, they should share a screenshot of the analysis (e.g., from G*Power).</p>
<div class="cell">
<div class="sourceCode" id="cb98"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">include_graphics</span>(<span class="st">&quot;figures/gpower_3w.png&quot;</span>)</span></code></pre></div>
<div class="cell-output-display">
<div id="fig-figure12" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/gpower_3w.png" class="img-fluid" style="width:100.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 12: Screenshot of G*Power interface with all required information to reproduce the power analysis for a one-way within-subject design with three 3 dependent groups.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Besides providing the analysis script or a screenshot, researchers should justify all decisions made during the power analysis—such as the chosen effect size and any other assumptions (e.g., correlation between measurements).</p>
<p>To improve the sample size justification regardless of the approach, researchers are encouraged to use the <a href="https://shiny.ieis.tue.nl/sample_size_justification/">Sample Size Justification Shiny App</a> which offers step-by-step guidance for reporting a priori power analyses and other types of sample size justification. Researchers should transparently justify the chosen effect size. Before using the app, readers are encouraged to read <span class="citation" data-cites="lakens_justification_2022">Daniël Lakens (<a href="#ref-lakens_justification_2022" role="doc-biblioref">2022a</a>)</span>. Briefly, the <a href="https://shiny.ieis.tue.nl/sample_size_justification/">Sample Size Justification Shiny App</a> covers the following steps:</p>
<ol type="1">
<li>Describe the population of interest and resource constraints. Clicking on “?” provides a detailed description of each question.</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure13" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/partA.png" class="img-fluid" style="width:100.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 13: Part A - Describe your population.
</figcaption>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li>Justify the effect size of interest based on the following categories:</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure14" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure14-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/partB.png" class="img-fluid" style="width:100.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure14-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 14: Part B - Justify which effect ssizes they consider meaningful to learn about.
</figcaption>
</figure>
</div>
</div>
</div>
<ol start="3" type="1">
<li>Specify your inferential goal. If your goal is to achieve a desired level of power, you should perform an a priori power analysis that includes all necessary details and ideally provided as reproducible code.</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure15" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure15-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/partC.png" class="img-fluid" style="width:100.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure15-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 15: Part C - Specify the inferential goal.
</figcaption>
</figure>
</div>
</div>
</div>
<ol start="4" type="1">
<li>Specify the total number of participants, observations per participant and explain the informational value of the planned study. Researchers can then download the the report as an html file so that it can be added as part of the preregistration of the study.</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div id="fig-figure16" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-figure16-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/partD.png" class="img-fluid" style="width:100.0%" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-figure16-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 16: Part D - Explain the informational value of the planned study.
</figcaption>
</figure>
</div>
</div>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-lakens_followup_bias" class="csl-entry" role="listitem">
Albers, Casper, and Daniël Lakens. 2018. <span>“When Power Analyses Based on Pilot Data Are Biased: <span>Inaccurate</span> Effect Size Estimators and Follow-up Bias.”</span> <em>Journal of Experimental Social Psychology</em> 74: 187–95. <a href="https://doi.org/10.1016/j.jesp.2017.09.004">https://doi.org/10.1016/j.jesp.2017.09.004</a>.
</div>
<div id="ref-bucss_software" class="csl-entry" role="listitem">
Anderson, Samantha F., and Ken Kelley. 2016. <span>“<span>BUCSS</span>: <span>Bias</span> and <span>Uncertainty Corrected Sample Size</span>.”</span> Comprehensive R Archive Network.
</div>
<div id="ref-anderson_sample_planning" class="csl-entry" role="listitem">
Anderson, Samantha F., Ken Kelley, and Scott E. Maxwell. 2017. <span>“Sample-<span>Size Planning</span> for <span>More Accurate Statistical Power</span>: <span>A Method Adjusting Sample Effect Sizes</span> for <span>Publication Bias</span> and <span>Uncertainty</span>.”</span> <em>Psychological Science</em> 28 (11): 1547–62. <a href="https://doi.org/10.1177/0956797617723724">https://doi.org/10.1177/0956797617723724</a>.
</div>
<div id="ref-anvari_sesoi" class="csl-entry" role="listitem">
Anvari, Farid, and Daniël Lakens. 2021. <span>“Using Anchor-Based Methods to Determine the Smallest Effect Size of Interest.”</span> <em>Journal of Experimental Social Psychology</em> 96: 104159. <a href="https://doi.org/10.1016/j.jesp.2021.104159">https://doi.org/10.1016/j.jesp.2021.104159</a>.
</div>
<div id="ref-bakker_rules_game" class="csl-entry" role="listitem">
Bakker, Marjan, Annette van Dijk, and Jelte M. Wicherts. 2012. <span>“The <span>Rules</span> of the <span>Game Called Psychological Science</span>.”</span> <em>Perspectives on Psychological Science</em> 7 (6): 543–54. <a href="https://doi.org/10.1177/1745691612459060">https://doi.org/10.1177/1745691612459060</a>.
</div>
<div id="ref-bakker_quality_poweranalysis" class="csl-entry" role="listitem">
Bakker, Marjan, Coosje L. S. Veldkamp, Marcel A. L. M. van Assen, Elise A. V. Crompvoets, How Hwee Ong, Brian A. Nosek, Courtney K. Soderberg, David Mellor, and Jelte M. Wicherts. 2020. <span>“Ensuring the Quality and Specificity of Preregistrations.”</span> <em>PLoS Biology</em> 18 (12): e3000937. <a href="https://doi.org/10.1371/journal.pbio.3000937">https://doi.org/10.1371/journal.pbio.3000937</a>.
</div>
<div id="ref-bartlett_jamovi" class="csl-entry" role="listitem">
Bartlett, James, and Sarah Charles. 2022. <span>“Power to the <span>People</span>: <span>A Beginner</span>’s <span>Tutorial</span> to <span>Power Analysis</span> Using Jamovi.”</span> <em>Meta-Psychology</em> 6 (November). <a href="https://doi.org/10.15626/MP.2021.3078">https://doi.org/10.15626/MP.2021.3078</a>.
</div>
<div id="ref-borm_2007" class="csl-entry" role="listitem">
Borm, George F., Jaap Fransen, and Wim A. J. G. Lemmens. 2007. <span>“A Simple Sample Size Formula for Analysis of Covariance in Randomized Clinical Trials.”</span> <em>Journal of Clinical Epidemiology</em> 60 (12): 1234–38. <a href="https://doi.org/10.1016/j.jclinepi.2007.02.006">https://doi.org/10.1016/j.jclinepi.2007.02.006</a>.
</div>
<div id="ref-brown_introduction_LMEM" class="csl-entry" role="listitem">
Brown, Violet A. 2021. <span>“An <span>Introduction</span> to <span>Linear Mixed-Effects Modeling</span> in <span>R</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 4 (1): 2515245920960351. <a href="https://doi.org/10.1177/2515245920960351">https://doi.org/10.1177/2515245920960351</a>.
</div>
<div id="ref-brysbaert_how_to_LMEM" class="csl-entry" role="listitem">
Brysbaert, Marc, and Dries Debeer. 2025. <span>“How to <span>Run Linear Mixed Effects Analysis</span> for <span>Pairwise Comparisons</span>? <span>A Tutorial</span> and a <span>Proposal</span> for the <span>Calculation</span> of <span>Standardized Effect Sizes</span>.”</span> <em>Journal of Cognition</em> 8 (1). <a href="https://doi.org/10.5334/joc.409">https://doi.org/10.5334/joc.409</a>.
</div>
<div id="ref-brysbaert_LMEM" class="csl-entry" role="listitem">
Brysbaert, Marc, and Michaël Stevens. 2018. <span>“Power <span>Analysis</span> and <span>Effect Size</span> in <span>Mixed Effects Models</span>: <span>A Tutorial</span>.”</span> <em>Journal of Cognition</em> 1 (1). <a href="https://doi.org/10.5334/joc.10">https://doi.org/10.5334/joc.10</a>.
</div>
<div id="ref-christogiannis_post-hoc" class="csl-entry" role="listitem">
Christogiannis, Christos, Stavros Nikolakopoulos, Nikolaos Pandis, and Dimitris Mavridis. 2022. <span>“The Self-Fulfilling Prophecy of Post-Hoc Power Calculations.”</span> <em>American Journal of Orthodontics and Dentofacial Orthopedics</em> 161 (2): 315–17. <a href="https://doi.org/10.1016/j.ajodo.2021.10.008">https://doi.org/10.1016/j.ajodo.2021.10.008</a>.
</div>
<div id="ref-ciria_umbrella_review" class="csl-entry" role="listitem">
Ciria, Luis F., Rafael Román-Caballero, Miguel A. Vadillo, Darias Holgado, Antonio Luque-Casado, Pandelis Perakakis, and Daniel Sanabria. 2023. <span>“An Umbrella Review of Randomized Control Trials on the Effects of Physical Exercise on Cognition.”</span> <em>Nature Human Behaviour</em> 7 (6): 928–41. <a href="https://doi.org/10.1038/s41562-023-01554-4">https://doi.org/10.1038/s41562-023-01554-4</a>.
</div>
<div id="ref-cook_mcid_2008" class="csl-entry" role="listitem">
Cook, Chad E. 2008. <span>“Clinimetrics <span>Corner</span>: <span>The Minimal Clinically Important Change Score</span> (<span>MCID</span>): <span>A Necessary Pretense</span>.”</span> <em>The Journal of Manual &amp; Manipulative Therapy</em> 16 (4): E82–83. <a href="https://doi.org/10.1179/jmt.2008.16.4.82E">https://doi.org/10.1179/jmt.2008.16.4.82E</a>.
</div>
<div id="ref-debruine_faux" class="csl-entry" role="listitem">
DeBruine, Lisa. 2023. <span>“Faux: <span>Simulation</span> for <span>Factorial Designs</span>.”</span> Zenodo. <a href="https://doi.org/10.5281/zenodo.7852893">https://doi.org/10.5281/zenodo.7852893</a>.
</div>
<div id="ref-debruine_mixed_effects" class="csl-entry" role="listitem">
DeBruine, Lisa M., and Dale J. Barr. 2021. <span>“Understanding <span>Mixed-Effects Models Through Data Simulation</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 4 (1): 2515245920965119. <a href="https://doi.org/10.1177/2515245920965119">https://doi.org/10.1177/2515245920965119</a>.
</div>
<div id="ref-hagger_multilab_2016" class="csl-entry" role="listitem">
Hagger, M. S., N. L. D. Chatzisarantis, H. Alberts, C. O. Anggono, C. Batailler, A. R. Birt, R. Brand, et al. 2016. <span>“A <span>Multilab Preregistered Replication</span> of the <span>Ego-Depletion Effect</span>.”</span> <em>Perspectives on Psychological Science</em> 11 (4): 546–73. <a href="https://doi.org/10.1177/1745691616652873">https://doi.org/10.1177/1745691616652873</a>.
</div>
<div id="ref-jane_guidelines_es" class="csl-entry" role="listitem">
Jané, Matthew B, Qinyu Xiao, Siu Kit Yeung, Flavio Azevedo, Mattan S Ben-Shachar, Aaron R Caldwell, Denis Cousineau, et al. 2024. <span>“Guide to <span>Effect Sizes</span> and <span>Confidence Intervals</span>.”</span> OSF. <a href="https://doi.org/10.17605/OSF.IO/D8C4G">https://doi.org/10.17605/OSF.IO/D8C4G</a>.
</div>
<div id="ref-kvarven_2020" class="csl-entry" role="listitem">
Kvarven, Amanda, Eirik Strømland, and Magnus Johannesson. 2020. <span>“Comparing Meta-Analyses and Preregistered Multiple-Laboratory Replication Projects.”</span> <em>Nature Human Behaviour</em> 4 (4): 423–34. <a href="https://doi.org/10.1038/s41562-019-0787-z">https://doi.org/10.1038/s41562-019-0787-z</a>.
</div>
<div id="ref-lakens_calculating_es" class="csl-entry" role="listitem">
Lakens, Daniel. 2013. <span>“Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and <span>ANOVAs</span>.”</span> <em>Frontiers in Psychology</em> 4: 863. <a href="https://doi.org/10.3389/fpsyg.2013.00863">https://doi.org/10.3389/fpsyg.2013.00863</a>.
</div>
<div id="ref-lakens_value_preregistration" class="csl-entry" role="listitem">
———. 2019. <span>“The Value of Preregistration for Psychological Science: <span>A</span> Conceptual Analysis.”</span> <em>心理学評論</em> 62 (3): 221–30.
</div>
<div id="ref-lakens_sequential_2014" class="csl-entry" role="listitem">
Lakens, Daniël. 2014. <span>“Performing High-Powered Studies Efficiently with Sequential Analyses.”</span> <em>European Journal of Social Psychology</em> 44 (7): 701–10. <a href="https://doi.org/10.1002/ejsp.2023">https://doi.org/10.1002/ejsp.2023</a>.
</div>
<div id="ref-lakens_equivalence_2017" class="csl-entry" role="listitem">
———. 2017. <span>“Equivalence <span>Tests</span>: <span>A Practical Primer</span> for t <span>Tests</span>, <span>Correlations</span>, and <span>Meta-Analyses</span>.”</span> <em>Social Psychological and Personality Science</em>, May. <a href="https://doi.org/10.1177/1948550617697177">https://doi.org/10.1177/1948550617697177</a>.
</div>
<div id="ref-lakens_justification_2022" class="csl-entry" role="listitem">
———. 2022a. <span>“Sample <span>Size Justification</span>.”</span> Edited by Don van Ravenzwaaij. <em>Collabra: Psychology</em> 8 (1): 33267. <a href="https://doi.org/10.1525/collabra.33267">https://doi.org/10.1525/collabra.33267</a>.
</div>
<div id="ref-lakens_sample_justification" class="csl-entry" role="listitem">
———. 2022b. <span>“Sample <span>Size Justification</span>.”</span> <em>Collabra: Psychology</em> 8 (1): 33267. <a href="https://doi.org/10.1525/collabra.33267">https://doi.org/10.1525/collabra.33267</a>.
</div>
<div id="ref-lakens_equivalence_2018" class="csl-entry" role="listitem">
Lakens, Daniël, Anne M. Scheel, and Peder M. Isager. 2018. <span>“Equivalence <span>Testing</span> for <span>Psychological Research</span>: <span>A Tutorial</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 1 (2): 259–69. <a href="https://doi.org/10.1177/2515245918770963">https://doi.org/10.1177/2515245918770963</a>.
</div>
<div id="ref-langenberg_tutorial" class="csl-entry" role="listitem">
Langenberg, Benedikt, Markus Janczyk, Valentin Koob, Reinhold Kliegl, and Axel Mayer. 2023. <span>“A Tutorial on Using the Paired t Test for Power Calculations in Repeated Measures <span>ANOVA</span> with Interactions.”</span> <em>Behavior Research Methods</em> 55 (5): 2467–84. <a href="https://doi.org/10.3758/s13428-022-01902-8">https://doi.org/10.3758/s13428-022-01902-8</a>.
</div>
<div id="ref-lenth_posthocpower_2007" class="csl-entry" role="listitem">
Lenth, R. 2007. <span>“Statistical Power Calculations.”</span> <em>Journal of Animal Science</em> 85 (April): E24–9. <a href="https://doi.org/10.2527/jas.2006-449">https://doi.org/10.2527/jas.2006-449</a>.
</div>
<div id="ref-murayama_2022" class="csl-entry" role="listitem">
Murayama, Kou, Satoshi Usami, and Michiko Sakaki. 2022. <span>“Summary-Statistics-Based Power Analysis: <span>A</span> New and Practical Method to Determine Sample Size for Mixed-Effects Modeling.”</span> <em>Psychological Methods</em> 27 (6): 1014–38. <a href="https://doi.org/10.1037/met0000330">https://doi.org/10.1037/met0000330</a>.
</div>
<div id="ref-murphy_minimum-effect-test_1999" class="csl-entry" role="listitem">
Murphy, Kevin R., and Brett Myors. 1999. <span>“Testing the Hypothesis That Treatments Have Negligible Effects: <span class="nocase">Minimum-effect</span> Tests in the General Linear Model.”</span> <em>Journal of Applied Psychology</em> 84 (2): 234–48. <a href="https://doi.org/10.1037/0021-9010.84.2.234">https://doi.org/10.1037/0021-9010.84.2.234</a>.
</div>
<div id="ref-perugini_critical_es_2025" class="csl-entry" role="listitem">
Perugini, Ambra, Filippo Gambarota, Enrico Toffalini, Daniël Lakens, Massimiliano Pastore, Livio Finos, and Gianmarco Altoè. 2025. <span>“The <span>Benefits</span> of <span>Reporting Critical-Effect-Size Values</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 8 (2): 25152459251335298. <a href="https://doi.org/10.1177/25152459251335298">https://doi.org/10.1177/25152459251335298</a>.
</div>
<div id="ref-perugini_safeguard" class="csl-entry" role="listitem">
Perugini, Marco, Marcello Gallucci, and Giulio Costantini. 2014. <span>“Safeguard <span>Power</span> as a <span>Protection Against Imprecise Power Estimates</span>.”</span> <em>Perspectives on Psychological Science</em> 9 (3): 319–32. <a href="https://doi.org/10.1177/1745691614528519">https://doi.org/10.1177/1745691614528519</a>.
</div>
<div id="ref-riesthuis_simulations" class="csl-entry" role="listitem">
Riesthuis, Paul. 2024. <span>“Simulation-<span>Based Power Analyses</span> for the <span>Smallest Effect Size</span> of <span>Interest</span>: <span>A Confidence-Interval Approach</span> for <span>Minimum-Effect</span> and <span>Equivalence Testing</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 7 (2): 25152459241240722. <a href="https://doi.org/10.1177/25152459241240722">https://doi.org/10.1177/25152459241240722</a>.
</div>
<div id="ref-scheel_excessive" class="csl-entry" role="listitem">
Scheel, Anne M., Mitchell R. M. J. Schijen, and Daniël Lakens. 2021. <span>“An <span>Excess</span> of <span>Positive Results</span>: <span>Comparing</span> the <span>Standard Psychology Literature With Registered Reports</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 4 (2): 1–12. <a href="https://doi.org/10.1177/25152459211007467">https://doi.org/10.1177/25152459211007467</a>.
</div>
<div id="ref-scheel_why_hypothesis" class="csl-entry" role="listitem">
Scheel, Anne M., Leonid Tiokhin, Peder M. Isager, and Daniël Lakens. 2020. <span>“Why <span>Hypothesis Testers Should Spend Less Time Testing Hypotheses</span>.”</span> <em>Perspectives on Psychological Science: A Journal of the Association for Psychological Science</em>, December, 1745691620966795. <a href="https://doi.org/10.1177/1745691620966795">https://doi.org/10.1177/1745691620966795</a>.
</div>
<div id="ref-senn_2021" class="csl-entry" role="listitem">
Senn, Stephen J. 2021. <span>“Determining the <span>Sample Size</span>.”</span> In <em>Statistical <span>Issues</span> in <span>Drug Development</span></em>, 241–64. John Wiley &amp; Sons, Ltd. <a href="https://doi.org/10.1002/9781119238614.ch13">https://doi.org/10.1002/9781119238614.ch13</a>.
</div>
<div id="ref-sommet_interaction" class="csl-entry" role="listitem">
Sommet, Nicolas, David L. Weissman, Nicolas Cheutin, and Andrew J. Elliot. 2023. <span>“How <span>Many Participants Do I Need</span> to <span>Test</span> an <span>Interaction</span>? <span>Conducting</span> an <span>Appropriate Power Analysis</span> and <span>Achieving Sufficient Power</span> to <span>Detect</span> an <span>Interaction</span>.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 6 (3): 25152459231178728. <a href="https://doi.org/10.1177/25152459231178728">https://doi.org/10.1177/25152459231178728</a>.
</div>
<div id="ref-stefan_big_little_lies" class="csl-entry" role="listitem">
Stefan, A. M., and Felix D. Schönbrodt. 2023. <span>“Big Little Lies: A Compendium and Simulation of p-Hacking Strategies.”</span> <em>Royal Society Open Science</em> 10 (2): 220346. <a href="https://doi.org/10.1098/rsos.220346">https://doi.org/10.1098/rsos.220346</a>.
</div>
<div id="ref-thibault_errors_power" class="csl-entry" role="listitem">
Thibault, Robert T., Emmanuel A. Zavalis, Mario Malički, and Hugo Pedder. 2024. <span>“An Evaluation of Reproducibility and Errors in Published Sample Size Calculations Performed Using <span>G</span>*<span>Power</span>.”</span> medRxiv. <a href="https://doi.org/10.1101/2024.07.15.24310458">https://doi.org/10.1101/2024.07.15.24310458</a>.
</div>
<div id="ref-westfall_2014" class="csl-entry" role="listitem">
Westfall, Jacob, David A. Kenny, and Charles M. Judd. 2014. <span>“Statistical Power and Optimal Design in Experiments in Which Samples of Participants Respond to Samples of Stimuli.”</span> <em>Journal of Experimental Psychology: General</em> 143 (5): 2020–45. <a href="https://doi.org/10.1037/xge0000014">https://doi.org/10.1037/xge0000014</a>.
</div>
<div id="ref-yuan_posthoc" class="csl-entry" role="listitem">
Yuan, Ke-Hai, and Scott Maxwell. 2005. <span>“On the <span>Post Hoc Power</span> in <span>Testing Mean Differences</span>.”</span> <em>Journal of Educational and Behavioral Statistics Summer</em> 30: 141–67. <a href="https://doi.org/10.3102/10769986030002141">https://doi.org/10.3102/10769986030002141</a>.
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->

</body>

</html>
